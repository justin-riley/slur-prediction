{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv,DataFrame,concat\n",
    "from sklearn.preprocessing import MultiLabelBinarizer,OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "#sqlc = SQLContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(sparse_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('extra_storage/project/lemmatized_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Collecting emoji\n",
      "  Using cached https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l-"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import string\n",
    "import emoji\n",
    "from unicodedata import name\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from pandas import Series\n",
    "\n",
    "#%%\n",
    "def remove_emoji(comment, replace_with_text=False):\n",
    "    '''\n",
    "    Helper function to remove emoji from a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:            str:    String to be cleaned\n",
    "    replace_with_text:  bool:   Whether or not the emoji will be \n",
    "                                    replaced or removed\n",
    "    Returns:\n",
    "    --------\n",
    "    str:    cleaned string\n",
    "    '''\n",
    "    if replace_with_text:\n",
    "        return replace_emoji(comment)\n",
    "    else:\n",
    "        return comment.encode('ascii','ignore').decode('ascii')\n",
    "\n",
    "def count_words(comment):\n",
    "    '''\n",
    "    Helper function to count the number of words in a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:       str: String whose words will be counted\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int:    number of words in string\n",
    "    '''\n",
    "    return len(comment.split())\n",
    "\n",
    "def get_grams(comment,n=2,keep_emoji_words=False):\n",
    "    '''\n",
    "    Returns n-grams for a sentence, optionally cleaning the string\n",
    "    in the process.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:            str:    sentence for which n-grams will be \n",
    "                                    made\n",
    "    n:                  int:    number of tokens to include in n-gram\n",
    "    keep_emoji_words:   bool:   whether emoji will be removed or \n",
    "                                    substituted with text \n",
    "                                    descriptions\n",
    "    Returns:\n",
    "    --------\n",
    "    list:   list of n-grams\n",
    "    '''\n",
    "    blob = TextBlob(clean_text(comment, keep_emoji_words=\\\n",
    "                                        keep_emoji_words))\n",
    "    return list([' '.join(wordlist) for wordlist in blob.ngrams(n)])\n",
    "# %%\n",
    "def clean_text(comment, keep_periods=True,\\\n",
    "                        keep_emoji_words=False):\n",
    "    '''\n",
    "    Removes all punctuation (and, optionally, emoji/non-ascii \n",
    "    characters) from a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:            str:    the string whose punctuation/emoji \n",
    "                                    will be removed\n",
    "    keep_periods:       bool:   whether or not periods will also be \n",
    "                                    removed\n",
    "    keep_emoji_words:   bool:   whether emoji will be removed or \n",
    "                                    replaced with string descriptions\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str:    cleaned text\n",
    "    '''\n",
    "    translation_dic = {key:None for key in string.punctuation}\n",
    "    if keep_periods:\n",
    "        del translation_dic['.']\n",
    "        tr_tab = str.maketrans(translation_dic)\n",
    "    else:\n",
    "        tr_tab = str.maketrans(translation_dic)\n",
    "    return remove_emoji(comment,keep_emoji_words).translate(tr_tab)\n",
    "\n",
    "def lemmatize(comment):\n",
    "    '''\n",
    "    Returns lemmatized version of reddit comment.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:        str:    comment to lemmatize\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    return_list:    str:  '''\n",
    "    pass\n",
    "def count_emoji(comment):\n",
    "    '''\n",
    "    Function that counts number of emoji in a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:    str:    String from which number of emoji will be \n",
    "                            counted and returned\n",
    "    Returns:\n",
    "    --------\n",
    "    int:    number of emoji present in string\n",
    "    '''\n",
    "    return sum([\n",
    "        1 for character in comment \n",
    "            if character in emoji.UNICODE_EMOJI.keys()\n",
    "    ])\n",
    "def replace_emoji(comment):\n",
    "    '''\n",
    "    Function to replace emoji in a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:    str:    String from which emoji will be replaced\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str:    Cleaned string where emoji have been repalced with ascii\n",
    "                characters describing the image\n",
    "    '''\n",
    "    return ''.join([\n",
    "        '_'.join(name(character).split())+' ' if character in\n",
    "        emoji.UNICODE_EMOJI else character for character\n",
    "        in comment\n",
    "    ])\n",
    "\n",
    "def stopwords_list(series,fraction = 0.2):\n",
    "    '''\n",
    "    Takes in a pandas.core.Series object, iterates over it, creating\n",
    "    a list of words, then finds the most frequently used words in the\n",
    "    corpus.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series:     pd.core.Series: Series whose words will be counted\n",
    "    fraction:   float: fraction of words to throw out\n",
    "\n",
    "    Returns:\n",
    "    list:   list of (fraction) most-frequently used words\n",
    "    '''\n",
    "    out = []\n",
    "    for elements in series:\n",
    "        cleaned = clean_text(elements,False,False)\n",
    "        num_words = count_words(cleaned)\n",
    "        if num_words > 1:\n",
    "            out.extend(cleaned.split())\n",
    "        elif num_words == 1:\n",
    "            out.append(cleaned)\n",
    "    ctr = [(word,count) for word,count in Counter(out).items()]\n",
    "    ctr.sort(key=lambda x:x[1])\n",
    "    ctr = ctr[::-1]\n",
    "    if not fraction:\n",
    "        return ctr\n",
    "    else:\n",
    "        cutoff_index = int(fraction*len(ctr))\n",
    "        stopwords = [word for word,number in ctr]\n",
    "        return stopwords[:cutoff_index]\n",
    "\n",
    "def series_grams(series,n=2):\n",
    "    '''\n",
    "    Function that returns a pandas.core.Series containing n-grams for\n",
    "    each row in the series that is passed to it.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    series: pd.core.series.Series: Series containing comments out of \n",
    "                                which n-grams are to be made\n",
    "    n:      int:            integer number of tokens to includ in \n",
    "                                each n-gram\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.core.series.Series\n",
    "    '''\n",
    "    out = []\n",
    "    for elements in series:        \n",
    "        out.append(get_ngrams(elements.lower(),n))\n",
    "    return Series(out)\n",
    "\n",
    "\n",
    "# %%\n",
    "def all_ngrams(series):\n",
    "    '''\n",
    "    Takes pandas.core.Series as argument, iterates over it, and \n",
    "    returns a set of all n-grams present in the series.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    series: pd.core.series.Series: series containing lists of ngrams\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    out:    set:            set of all n-grams present in series\n",
    "    '''\n",
    "\n",
    "    out = set()\n",
    "    for elements in series:\n",
    "        for grams in elements:\n",
    "            out.add(grams)\n",
    "    return out\n",
    "\n",
    "def make_dummies(df, col_name):\n",
    "    '''\n",
    "    Makes dummy columns from df column containing list of n-grams.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df:         pd.core.frame.DataFrame:\n",
    "    col_name:   str:    name of column from which dummies will be made\n",
    "\n",
    "    Returns:\n",
    "    pandas.core.frame.DataFrame\n",
    "    '''\n",
    "\n",
    "    gram_set = all_ngrams(df[col_name])\n",
    "    for grams in gram_set:\n",
    "        df[grams] = Series([0]*df.shape[0])\n",
    "    for idx, row in df.iterrows():\n",
    "        for grms in row[col_name]:\n",
    "            df.loc[idx,grms] = 1\n",
    "    del df[col_name]\n",
    "    return df\n",
    "\n",
    "def kill_stopwords(comment):\n",
    "    return ' '.join([word for word in clean_text(comment).split() if word not in new_throw])\n",
    "\n",
    "def get_ngrams(comment,n=2):\n",
    "    return [' '.join(w) for s in TextBlob(comment).sentences for w in s.ngrams(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['2-gram'] = series_grams(data['reduced_sw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('reduced_2_gram.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [(person,count) for person,count in ctr.items()]\n",
    "authors.sort(key=lambda x:x[1])\n",
    "ppl = [author for author,count in authors[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = set([author for author,count in authors[::-1][1:] if count > 1900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['author'].isin(ppl)\n",
    "subset = data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (77477, 363491) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-b11237b99942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2-gram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (77477, 363491) and data type int64"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reduced_sw'] = data['lemma'].map(kill_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Im guess buy Steam GOG Origin Uplay Whats Wind...\n",
       "1                Bitcoins flaw inflation investment invest.\n",
       "2                               That retard. So many wrong.\n",
       "3                            The Bitcoin doom deflationary.\n",
       "4                                      Well caught so work.\n",
       "                                ...                        \n",
       "799056                                   Huh pretty runner.\n",
       "799057                                           Such game.\n",
       "799058        It Ive bowling ground I guess probably thing.\n",
       "799059                                        Id NZ I well.\n",
       "799060                                                 Yes.\n",
       "Name: reduced_sw, Length: 799061, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reduced_sw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1a1732eb1949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reduced_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reduced_sw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3826\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3827\u001b[0m         \"\"\"\n\u001b[0;32m-> 3828\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3829\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-c64b83b9fb2d>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(comment, keep_periods, keep_emoji_words)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mtr_tab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslation_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mremove_emoji\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_emoji_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_tab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-c64b83b9fb2d>\u001b[0m in \u001b[0;36mremove_emoji\u001b[0;34m(comment, replace_with_text)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreplace_emoji\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "data['reduced_count'] = data['reduced_sw'].map(list).map(clean_text).map(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'origin', 'store.', 'buy', 'whats', 'guess'}\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "{'inflation', 'invest.', 'investment', 'flaw', 'bitcoins'}\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "{'retard.', 'many', 'so', 'wrong.'}\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "{'deflationary.', 'doom'}\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "{'work.', 'so', 'caught'}\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "{'tz.', 'prime.', 'timezones.', 'lose'}\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "{'job.', 'most'}\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n",
      "+--------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "for i,comment in enumerate(data['reduced_sw']):\n",
    "    print(comment)\n",
    "    print('+--------------------------------------------------+')    \n",
    "    print('+--------------------------------------------------+')    \n",
    "    print('+--------------------------------------------------+')\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_list = stopwords_list(data['lemma'],None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_throw = set()\n",
    "for w in throwout_words:\n",
    "    if isinstance(w,str):\n",
    "        new_throw.add(w.lower())\n",
    "    else:\n",
    "        new_throw.add(w[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'especiall',\n",
       " 'borja',\n",
       " 'Spys',\n",
       " 'sirection',\n",
       " 'YouhttpsiimgurcomPKeLzVQpng',\n",
       " 'downthread',\n",
       " 'Atlantichttpwwwtheatlanticcomtechnologyarchive201202imbeingfollowedhowgoogleand104othercompaniesaretrackingmeontheweb253758',\n",
       " 'Emerys',\n",
       " 'propagandaey',\n",
       " 'Communisms',\n",
       " 'LNB',\n",
       " 'IDDMhttpsinvisiversewonderhowtocomnewsrootcausetype1diabetescouldbecommonchildhoodviralinfection0175880',\n",
       " 'Cornflakes',\n",
       " 'antigunantimedia',\n",
       " 'sorrys',\n",
       " 'relgion',\n",
       " 'ghosthttpiimgurcomn2OqGpng',\n",
       " 'Baldness',\n",
       " 'Abaya',\n",
       " 'sohttpiimgurcom2B9lSPrjpg',\n",
       " 'Mariam',\n",
       " 'Qwop',\n",
       " 'hada',\n",
       " 'httpiimgurcomOUPR92bljpg',\n",
       " 'hangwoman',\n",
       " 'Remi',\n",
       " 'teoll',\n",
       " 'Adjusted',\n",
       " 'ROD',\n",
       " '0x67C2',\n",
       " 'Hsus',\n",
       " 'udilligafbazinga',\n",
       " 'Frderungsbudget',\n",
       " 'invents',\n",
       " 'Teleported',\n",
       " 'httpstimecom2822290tiananmensquaremassacrefactstime',\n",
       " 'censorthrottle',\n",
       " 'NSFWyou',\n",
       " 'prevalemt',\n",
       " '20032018',\n",
       " 'Ubis',\n",
       " 'feeeeeeeeemales',\n",
       " 'rcornouija',\n",
       " 'peoplepeople',\n",
       " 'Godzirra',\n",
       " 'gulliable',\n",
       " 'terrrist',\n",
       " 'loweredhttpsenwikipediaorgwikiCSSShenandoahThelastloweringoftheConfederateflag',\n",
       " 'hulkenberg',\n",
       " 'Shiitty',\n",
       " 'httpswwwyoutubecomwatchvBrQw2TKXq6o',\n",
       " 'Rothko',\n",
       " 'Xoxo',\n",
       " 'Metastuff',\n",
       " 'unseasoned',\n",
       " 'httpiimgurcomGqtqIV3png',\n",
       " 'dissatisfy',\n",
       " 'imaju',\n",
       " 'USCitizen',\n",
       " 'Joined',\n",
       " 'MEETS',\n",
       " 'thingwish',\n",
       " 'trailerad',\n",
       " 'unqualify',\n",
       " 'afrogto',\n",
       " 'blameable',\n",
       " 'HIGHEST',\n",
       " 'wasists',\n",
       " 'polandballs',\n",
       " 'melamine',\n",
       " 'httpsenwikipediaorgwikiListofanarchistcommunities',\n",
       " 'NOBAMA',\n",
       " 'icchy',\n",
       " 'onehttpstwittercomPontifexstatus975348596651339777',\n",
       " 'pickandchoose',\n",
       " 'preeminent',\n",
       " 'Kindleetc',\n",
       " 'RuneScape',\n",
       " 'Abruzzan',\n",
       " 'ruglike',\n",
       " 'amazoncas',\n",
       " 'httpswwwsangiingojpjapanesejoho1kouseiengmembersindexhtm',\n",
       " 'httpswwwstaplescomsbdcontentcopyandprintbusinesscardshtml',\n",
       " 'i2p',\n",
       " 'riskrewardROI',\n",
       " 'Nutshell',\n",
       " 'Holllyyyy',\n",
       " 'PreCalc',\n",
       " 'maddog',\n",
       " 'yuuuuugggeeeee',\n",
       " 'CtrlS',\n",
       " 'packeddecorated',\n",
       " 'whoreshttpiimgurcomOdhwQN2jpg',\n",
       " 'Sksksksk',\n",
       " 'FAAAAATHAAAAAAAAAAAAAAAHHHHHH',\n",
       " 'Awwhh',\n",
       " 'Pusher',\n",
       " 'jealousdefensive',\n",
       " 'holstered',\n",
       " '5001000',\n",
       " 'YW',\n",
       " 'Midwestdiet',\n",
       " 'TSIM',\n",
       " 'Fucksakes',\n",
       " 'rustyhttptranslationbabyloncomfrenchtoenglishaccusons',\n",
       " 'wrestlefuck',\n",
       " 'Patatas',\n",
       " 'ASSP',\n",
       " 'dumbshits',\n",
       " 'everrancid',\n",
       " 'Wernt',\n",
       " 'dealshttpsyoutube2TobaO46Bot35',\n",
       " 'Estevez',\n",
       " 'Skipjacks',\n",
       " 'Ahthe',\n",
       " 'RNA',\n",
       " 'Knifebowl',\n",
       " 'p4',\n",
       " 'fallacyThat',\n",
       " 'Eved',\n",
       " 'onko',\n",
       " 'EULAs',\n",
       " 'Herehttpmrreevescomkeanureevesnortonlastnight',\n",
       " 'ocassions',\n",
       " 'Gooodbye',\n",
       " 'nonalarming',\n",
       " 'Rabble',\n",
       " 'cavill',\n",
       " 'callus',\n",
       " 'Zool',\n",
       " 'Shy',\n",
       " 'Sourcehttpwwwmerriamwebstercomdictionaryattractive',\n",
       " 'webbrowser',\n",
       " 'uccehowell',\n",
       " 'httpswebarchivenationalarchivesgovuk20080206062728httpwwwfcogovukservletFrontpagenameOpenMarketXcelerateShowPagecPagecid1007029394365aKCountryProfileaid1018721190906',\n",
       " 'FUNNEH',\n",
       " 'Surprises',\n",
       " 'choppah',\n",
       " 'TREMENDOUS',\n",
       " 'Yarr',\n",
       " 'mangrovelined',\n",
       " 'ASSHOE',\n",
       " 'armydo',\n",
       " '51l0lbs',\n",
       " 'Barankovic',\n",
       " 'LEADS',\n",
       " 'herehttpwwwyoutubecomwatchvo99pXoawt8',\n",
       " 'networker',\n",
       " 'understandto',\n",
       " 'lagomorph',\n",
       " 'addressDNS',\n",
       " 'nunu',\n",
       " 'countrieshttpswwwredditcomrAskHistorianscomments2fwdynisthereanyevidenceofsovietcommunist',\n",
       " 'nonaffiliates',\n",
       " 'OTown',\n",
       " 'httpwwwconstitutionorgconswellreguhtm',\n",
       " 'lunker',\n",
       " 'dyvet',\n",
       " 'Larsson',\n",
       " 'agronat',\n",
       " 'raring',\n",
       " 'pixellated',\n",
       " 'Lactase',\n",
       " 'Pointitis',\n",
       " 'Delivershttpcloud3steampoweredcomugc505821122870245314023A9D7E179C3F2F759CECA09D5147ED5CD194BE',\n",
       " '6ml4y05httpfitetvinvite6ml4y05',\n",
       " 'hhhehehe',\n",
       " 'aMEriCaNS',\n",
       " 'crics',\n",
       " 'Praexology',\n",
       " 'feethttpwwwwolframalphacominputiunitedstateslandarea2Fworldpopulation',\n",
       " 'Dictionarycom',\n",
       " 'wau',\n",
       " 'footwell',\n",
       " 'pronegocio',\n",
       " '141k',\n",
       " 'moonshard',\n",
       " 'Nirmala',\n",
       " 'civicminded',\n",
       " 'lobotimization',\n",
       " 'httpwwwmemecreatororgmemesomeoneknowsart',\n",
       " 'httpswwwhealthlinecomhealthnewsheresthedrugsthatcanshowupindrinkingwater',\n",
       " 'Wonderwoman',\n",
       " 'hypervegan',\n",
       " 'uroscid',\n",
       " 'httpswwwgooglecomampsmobilenytimescom20180327worldasiakimjongunchinanorthkoreaamphtml',\n",
       " 'halflisp',\n",
       " 'awshit',\n",
       " 'conversant',\n",
       " 'Sprinkles',\n",
       " 'repaybanned',\n",
       " 'httpprofilesflyinggoatmancomindexphpStandardEditsFlyinggoatmansEdits',\n",
       " 'politicsreligion',\n",
       " 'TILhttptvtropesorgpmwikipmwikiphpMainNeverTheSelvesShallMeet',\n",
       " 'Uigurs',\n",
       " 'ujoeker1111',\n",
       " 'rrestofthefuckingowl',\n",
       " 'shopomg',\n",
       " 'thoughtfree',\n",
       " 'capspayforusage',\n",
       " 'celta',\n",
       " 'Gotemmm',\n",
       " 'stepson',\n",
       " 'Redditdom',\n",
       " 'Leafers',\n",
       " '83493',\n",
       " 'gohttpswwwscottscomsitesgfilesoydgjc106filesstylesscottsassetimage720440publicassetimagescompressedBentgrassjpgitoky8WmaAoH',\n",
       " 'workwhich',\n",
       " 'uTheMightyGaulmessageI',\n",
       " 'Reviss',\n",
       " 'attourney',\n",
       " 'squovals',\n",
       " 'httpswwwthestarcomnewsinsight20070825abriefhistoryofagentsprovocateurshtml',\n",
       " 'Trumo',\n",
       " 'chainhttpseswikipediaorgwikiCilicio',\n",
       " 'Tillamook',\n",
       " 'privatemusic',\n",
       " '180ppm',\n",
       " 'surveillanced',\n",
       " 'bradberry',\n",
       " 'httpsenmwikipediaorgwikiChibokschoolgirlskidnapping',\n",
       " 'boughtatagasstation',\n",
       " '230000',\n",
       " '4278',\n",
       " '6spd',\n",
       " 'fluidly',\n",
       " 'GPFans',\n",
       " 'chantepie',\n",
       " 'Codependants',\n",
       " 'comstitution',\n",
       " '4k60hz',\n",
       " 'rparadoxplaza',\n",
       " 'urticaria',\n",
       " 'Exceeds',\n",
       " 'httpswwwhrworgenreports20040713baddreams0',\n",
       " 'Mamaw',\n",
       " 'ameen',\n",
       " 'deadmow5',\n",
       " 'Sandradan',\n",
       " 'INVASION',\n",
       " 'uniknik2121',\n",
       " 'WowISO',\n",
       " 'weekender',\n",
       " 'NSAID',\n",
       " 'sha1passwordsalt',\n",
       " 'CRAVE',\n",
       " 'rrandomactsofpizza',\n",
       " 'Convergence',\n",
       " 'superedgy',\n",
       " 'DUPLOhttpimgurcomWfVWJxU',\n",
       " 'thisthatthe',\n",
       " 'drivetime',\n",
       " 'Mustafar',\n",
       " 'GALLILEOOOO',\n",
       " 'DRESS',\n",
       " 'scandallous',\n",
       " 'seppo',\n",
       " 'Coma',\n",
       " 'Caliph',\n",
       " 'httpwwwquotationspagecomquote36403html',\n",
       " 'Legendshttpswwwengadgetcom20151217leagueoflegendsfullyownedbytencent',\n",
       " 'homs',\n",
       " 'Isus',\n",
       " 'Eigo',\n",
       " 'dudettes',\n",
       " 'Scarestyle',\n",
       " 'Rafik',\n",
       " 'selfshot',\n",
       " 'rquarantinethefairersex',\n",
       " 'osho',\n",
       " 'freddie',\n",
       " 'HIs',\n",
       " 'videohttpsyoutubee8tpzgaZyzg',\n",
       " 'Nuns',\n",
       " 'Paypoint',\n",
       " 'batfamily',\n",
       " 'DGJ',\n",
       " 'httpsiimgurcomxP6CR2Ejpg',\n",
       " 'Immodium',\n",
       " 'abdullah',\n",
       " '100Gb',\n",
       " 'backtoback',\n",
       " 'foulplay',\n",
       " 'NorthKorean',\n",
       " '62C',\n",
       " 'tyle',\n",
       " 'Bendersky',\n",
       " 'FeeFees',\n",
       " 'Weeeeerrrnstrom',\n",
       " 'posumnjo',\n",
       " 'CJTFMEwhich',\n",
       " 'httpsiimgurcommxI5oaepng',\n",
       " 'httpsenwikipediaorgwikiJourneymanyears',\n",
       " 'DioHolyDiver83s',\n",
       " 'IdiotLoads',\n",
       " 'esqueleto',\n",
       " 'Kihgffghljv',\n",
       " 'reallylongtoreallyshort',\n",
       " 'occultism',\n",
       " 'CiA',\n",
       " 'tkd',\n",
       " 'thesehttpimgurcomfBu1dIW',\n",
       " 'lifehttpimgurcomaBBGla',\n",
       " 'righthttpwwwlatimescomlocallanowlamelnucdavislindakatehireturns20170801storyhtml',\n",
       " '2httpsenwikipediaorgwindexphptitleAtelierElieTheAlchemistofSalburg2actioneditredlink1',\n",
       " 'aheadopened',\n",
       " 'Mechromancer',\n",
       " 'Uus',\n",
       " 'lushux',\n",
       " 'httpswwwredditcomrpicscomments5wqyi0meetingdaddywithkellyannedechylkcontext3',\n",
       " 'Stinky',\n",
       " 'prendre',\n",
       " 'STREAMS',\n",
       " 'httpswwwyoutubecomwatchvwWhtcU4xAM',\n",
       " 'quityourbullshit',\n",
       " 'Schizophrenic',\n",
       " 'KINDLY',\n",
       " 'aircrew',\n",
       " 'IGNORED',\n",
       " 'saith',\n",
       " 'unshaped',\n",
       " 'feen',\n",
       " 'pescado',\n",
       " 'NoI',\n",
       " 'navigator',\n",
       " 'middlelevel',\n",
       " 'proteambill',\n",
       " 'GODBless',\n",
       " 'sheps',\n",
       " 'traduce',\n",
       " 'pouf',\n",
       " 'onealong',\n",
       " 'Arrrrrr',\n",
       " 'rihatethisfuckingmeme',\n",
       " 'karmaing',\n",
       " 'httpswwwgooglecomampsfortunecom20170315rachelmaddowtrumptaxesamp',\n",
       " 'rshino',\n",
       " 'actoranchor',\n",
       " 'bowman',\n",
       " 'Godhttpwwwquickmemecomimgb6b62702dc20fa573dfe833e8e8ad0518d3462ced2404a9d46bce5dcc9c65a7090jpg',\n",
       " 'sTePhAneeeee',\n",
       " 'stt',\n",
       " 'universitycollege',\n",
       " 'BLUFF',\n",
       " 'Croix',\n",
       " 'Friendlys',\n",
       " 'trumpservative',\n",
       " 'smolettes',\n",
       " '40mi',\n",
       " 'Dames',\n",
       " 'Hux',\n",
       " 'Cancels',\n",
       " 'CDDA',\n",
       " 'EVERYONEhttpiimgurcomUnX6Mgif',\n",
       " 'disenfranchises',\n",
       " 'Porkchop',\n",
       " 'RJThe',\n",
       " 'Hermoine',\n",
       " 'httpswwwredditcomrmoviescommentsddnua4after40hofworkifinishedmycoloredpencils',\n",
       " 'voir',\n",
       " 'inflige',\n",
       " 'ForceshttpsenmwikipediaorgwikiTigerForces',\n",
       " 'sarah',\n",
       " 'alQaedas',\n",
       " 'sexwhatever',\n",
       " 'Splashytoss',\n",
       " 'modfree',\n",
       " 'cooleasy',\n",
       " 'universesof',\n",
       " 'Omnis',\n",
       " 'nonincarcerated',\n",
       " 'meaninglessness',\n",
       " 'BoB',\n",
       " 'schlut',\n",
       " 'ThreeDog',\n",
       " 'cole',\n",
       " 'Hellfuck',\n",
       " 'Hora',\n",
       " 'spraypainting',\n",
       " 'shrednivashtar',\n",
       " 'Poffertjes',\n",
       " 'whoremoms',\n",
       " 'httpsyoutubeW3VJPKOQjUw',\n",
       " 'worshipful',\n",
       " 'yyyymmdd',\n",
       " 'workprogram',\n",
       " '3001200',\n",
       " 'kwh',\n",
       " 'Ogunsola',\n",
       " 'httpscdn04carsforsalecom3457416336720261514425000jpg',\n",
       " 'hydroxyzine',\n",
       " 'Snyders',\n",
       " 'Zark',\n",
       " 'canceledhttpswwwbbccomnewsworldasiachina36457450',\n",
       " 'Toga',\n",
       " 'furtherance',\n",
       " 'lioness',\n",
       " 'zeno',\n",
       " 'feminiellihttpsenwikipediaorgwikiFemminiello',\n",
       " 'mediashills',\n",
       " 'Grinder',\n",
       " 'Fundraising',\n",
       " 'greenwashing',\n",
       " 'photochunking',\n",
       " 'quickprofessional',\n",
       " 'Smilehttpiimgurcomztx9gvKjpg',\n",
       " 'sycophantic',\n",
       " 'dancingmadkoschei',\n",
       " 'radiationinduced',\n",
       " 'ODining',\n",
       " 'carrelated',\n",
       " 'uShyDualism',\n",
       " 'httpwwwyoutubecomwatchvKTKI9OUGVGU',\n",
       " 'springy',\n",
       " 'linkhttpglaitdeviantartcom',\n",
       " 'Interclass',\n",
       " 'SAUDI',\n",
       " 'matterstill',\n",
       " 'canton',\n",
       " 'plastique',\n",
       " 'Opposuits',\n",
       " 'tobaccoalcohol',\n",
       " 'tooooooooomuch',\n",
       " 'schlub',\n",
       " 'Chives',\n",
       " 'therefinancially',\n",
       " 'damnnn',\n",
       " 'Talentless',\n",
       " 'Yoyos',\n",
       " '04303',\n",
       " 'Motorcycles',\n",
       " 'Ramplowered',\n",
       " 'burnerpocolypse',\n",
       " 'podes',\n",
       " 'CatholicismChristianity',\n",
       " 'confirme',\n",
       " '845am',\n",
       " 'Nagels',\n",
       " 'islamaphobia',\n",
       " 'timehttpiimgurcomLyLfrItjpg',\n",
       " 'aubergine',\n",
       " 'agribusiness',\n",
       " '01101101',\n",
       " 'Lynchs',\n",
       " 'Mn',\n",
       " 'dificult',\n",
       " 'Rhys',\n",
       " 'allbondo',\n",
       " 'httpiimgurcomr4hGqvijpg',\n",
       " 'gubberment',\n",
       " 'Cmonif',\n",
       " 'tradetechnologyeconomic',\n",
       " 'illegitimately',\n",
       " 'alixir',\n",
       " 'Arabella',\n",
       " 'McAwesome',\n",
       " 'httpiimgurcom2iMhTxljpg',\n",
       " 'onece',\n",
       " 'ired',\n",
       " 'nonexhaustibe',\n",
       " 'C64',\n",
       " 'rjustfuckmyshitup',\n",
       " 'occupywst',\n",
       " 'Dawber',\n",
       " 'Denton',\n",
       " 'Bettman',\n",
       " 'immatureincompetent',\n",
       " 'youhttpiimgurcoms9Phhjpg',\n",
       " 'thenewamerica',\n",
       " 'enoughhence',\n",
       " 'MrTulip',\n",
       " 'httpwwwchicagoharborsinfo201120Harbor20Feespdf',\n",
       " 'AAAAAND',\n",
       " 'amazoncomhttpwwwamazoncomMilitaryCapsVietnamVeteranBaseballdpB000N5CP0U',\n",
       " 'Briana',\n",
       " 'principlethe',\n",
       " 'Impromptu',\n",
       " 'nonzeitarbeit',\n",
       " 'EhhhhI',\n",
       " 'seminew',\n",
       " 'HAHAHAHAHAHAHAHAHAHAHAH',\n",
       " 'IMPAIRED',\n",
       " 'Excelling',\n",
       " 'nonshield',\n",
       " '600750',\n",
       " 'indpendants',\n",
       " 'httpwwwheraldsuncomaublogsandrewboltwikileaksshowsmediahelpingclintonnewsstory86a4b6e1f8307aa32286251daf8023af',\n",
       " 'httpsmphysorgnews201105nuclearpowerworldenergyhtml',\n",
       " 'roams',\n",
       " 'pigshttpenwikipediaorgwikiNewMovementMeretz',\n",
       " 'MANvsGAME',\n",
       " '4151221',\n",
       " 'Amongst',\n",
       " 'httpxkcdcom566',\n",
       " 'YeshttpsiimgurcomsGDvO8pjpg',\n",
       " 'withby',\n",
       " 'Randstad',\n",
       " 'Accuracywise',\n",
       " 'Yandex',\n",
       " 'govpolice',\n",
       " 'Hundley',\n",
       " 'themm',\n",
       " 'GAWKER',\n",
       " 'Rheiney',\n",
       " 'JoAnn',\n",
       " 'bigstar',\n",
       " 'personhttpimgurcom2CBmR',\n",
       " 'HKCP',\n",
       " 'legskneeships',\n",
       " 'ThishttpiimgurcomyKt1DGojpg',\n",
       " 'cookedmade',\n",
       " 'waterhole',\n",
       " 'indemic',\n",
       " 'buerocracy',\n",
       " 'lifecost',\n",
       " 'agressively',\n",
       " 'EMPs',\n",
       " 'ebotdz',\n",
       " 'dowvoted',\n",
       " 'whilft',\n",
       " '2Modern',\n",
       " 'YesNo',\n",
       " 'vegophiles',\n",
       " '929930',\n",
       " 'tootski',\n",
       " 'ADVANCED',\n",
       " 'machiavellian',\n",
       " 'ProgressiveSounds',\n",
       " 'MontrealRacingcom',\n",
       " 'Gulch',\n",
       " 'httpsimgurcomQvMHEBQ',\n",
       " 'doesntmean',\n",
       " '60days',\n",
       " 'rIndivisibleGuide',\n",
       " 'durianriders',\n",
       " 'DECIDE',\n",
       " 'httpsiimgurcom3Mr6QLRjpg',\n",
       " 'pfps',\n",
       " 'httpwwwredditcomrpicscomments2ozzisundercovercoppointsgunatreutersphotographercmsfii3',\n",
       " 'quals',\n",
       " 'URLS',\n",
       " 'interferencehttpsliberationschoolorgtiananmenthemassacrethatwasnt',\n",
       " 'MacKenzie',\n",
       " 'firangi',\n",
       " 'httpsi1wpcomwwwbrookingseduwpcontentuploads201701ccf20170201reeves1pngw768crop02C0px2C1002C9999pxssl1',\n",
       " 'paddler',\n",
       " 'Fuoh',\n",
       " 'psychoanalyze',\n",
       " 'Governmentrun',\n",
       " 'Yhea',\n",
       " 'Aiyanas',\n",
       " 'Morelands',\n",
       " 'Dooby',\n",
       " 'ICANNaccredited',\n",
       " '9955466',\n",
       " 'FUCCK',\n",
       " 'httpsiimgurcomgE8VOBNgif',\n",
       " 'pickswap',\n",
       " 'Kangertech',\n",
       " '168000',\n",
       " 'fromhttpsikymcdncomphotosimagesoriginal001068818f32png',\n",
       " 'giantgfycatcom',\n",
       " '30day',\n",
       " 'RUBY',\n",
       " 'Awwws',\n",
       " 'achoo',\n",
       " 'SEXISM',\n",
       " 'DEVALUING',\n",
       " 'ARPGS',\n",
       " '9979',\n",
       " 'Hibs',\n",
       " 'BRINGIN',\n",
       " 'unmeasureable',\n",
       " 'rdcx',\n",
       " 'HereshttpswwwnbcdfwcomnewslocalRichardsonSchoolBusDriverSurprisesStudentswithGifts503420831html',\n",
       " 'CHRISTMASES',\n",
       " 'ZigBee',\n",
       " 'Thomson',\n",
       " 'McLintock',\n",
       " 'ufuzzysalad',\n",
       " 'midwesterners',\n",
       " 'WoWS',\n",
       " 'chadded',\n",
       " 'sociocultural',\n",
       " 'aroundlogic',\n",
       " 'Shihuahua',\n",
       " 'myyourour',\n",
       " 'shoujo',\n",
       " 'jedburghttpwwwredditcomrWTFcommentseaqnfpardonmebut5000downvoteswtfisworldnewsforc16oq1w',\n",
       " 'unterstelle',\n",
       " 'instagrams',\n",
       " 'rtruefilm',\n",
       " 'OBESITY',\n",
       " 'commenthttpswwwredditcomrpicscomments73w8zbthismantookabulletwhileprotectingmysisterdnttl6fcontext10',\n",
       " 'Formed',\n",
       " 'altfolkloreurban',\n",
       " 'Dorothys',\n",
       " 'Khi',\n",
       " 'Sgts',\n",
       " 'ChokalIngam',\n",
       " 'Equalists',\n",
       " 'passiontrue',\n",
       " 'Mollusks',\n",
       " 'Reirden',\n",
       " 'u1sttimeverbaldiarrhe',\n",
       " 'rrarepuppers',\n",
       " 'midriff',\n",
       " 'Posteur',\n",
       " 'umixingu',\n",
       " 'ecen',\n",
       " 'posthttpsnpredditcomrHighQualityGifscommentsayj9kdtodaywithoutanypriorwarningiwasbannedfromei171qb',\n",
       " 'Kasmina',\n",
       " 'appreaciated',\n",
       " 'HiGhEr',\n",
       " 'IGNORANCE',\n",
       " '1817',\n",
       " 'Swapper',\n",
       " 'figureoffour',\n",
       " 'Hellephant',\n",
       " 'Memento',\n",
       " 'Ikes',\n",
       " 'companyoffers',\n",
       " 'Vanced',\n",
       " 'MrTibbs',\n",
       " 'Amphiprion',\n",
       " 'ghostdriver',\n",
       " '2329mukvoted',\n",
       " 'MrAlexaBliss',\n",
       " 'Nonretractable',\n",
       " 'Pelicans',\n",
       " 'playbookhttpwwwredditcomrSJWNEWS',\n",
       " 'couldtake',\n",
       " 'EDG',\n",
       " 'Saskatoon',\n",
       " 'deliverey',\n",
       " 'xoxox',\n",
       " 'Bastilla',\n",
       " 'barrem',\n",
       " 'Olawakandi',\n",
       " 'chicki',\n",
       " 'nonbattleground',\n",
       " '101014',\n",
       " 'prounwanted',\n",
       " 'weaponsfentanyl',\n",
       " 'Gheeeaaaaay',\n",
       " 'wiggum',\n",
       " 'lenticular',\n",
       " 'everify',\n",
       " 'squillions',\n",
       " 'prophylactically',\n",
       " 'dealand',\n",
       " 'postcredits',\n",
       " 'eastridge',\n",
       " 'Shatnado',\n",
       " 'airpots',\n",
       " 'ContraAffair',\n",
       " 'emitter',\n",
       " 'loamy',\n",
       " 'thankfull',\n",
       " 'Grips',\n",
       " 'DIvoire',\n",
       " 'uGhostNightgown',\n",
       " 'Espeons',\n",
       " 'BHOQWISOwaxshatterwhateveryouwannacallit',\n",
       " 'PCMAC',\n",
       " 'Halal',\n",
       " 'Lethani',\n",
       " 'Jihadi',\n",
       " 'antiSatan',\n",
       " 'antimalarial',\n",
       " 'ucyberartz',\n",
       " 'httpswwwredditcomr2meirl4meirlcomments6wbbc12meirl4meirlutmcontentcommentsutmmediumhotutmsourceredditutmnameall',\n",
       " 'crondoms',\n",
       " 'NotAllSaudis',\n",
       " 'giggley',\n",
       " 'httpdoesthedogdiecom',\n",
       " 'contes',\n",
       " 'Cirellos',\n",
       " 'hottt',\n",
       " 'BREATHING',\n",
       " 'Shrimps',\n",
       " 'humpf',\n",
       " 'chubbiness',\n",
       " 'Drippy',\n",
       " 'tenyearold',\n",
       " 'groso',\n",
       " 'XxN00b5L4Y3RxX',\n",
       " 'uJusticeServed',\n",
       " 'Orks',\n",
       " 'Antiperspirant',\n",
       " 'httpenwikipediaorgwikiThePirateBayIncidents',\n",
       " 'girlfriendhttpimgurcomnfyL5If',\n",
       " 'unpassable',\n",
       " 'uninsulated',\n",
       " '8TB',\n",
       " 'rjeepdogs',\n",
       " 'ujohnnyboiandco',\n",
       " 'Starbreeze',\n",
       " 'schoolhomeworketc',\n",
       " 'remoaner',\n",
       " 'highrevenue',\n",
       " 'dasracistjpg',\n",
       " 'wonlose',\n",
       " 'liein',\n",
       " 'stong',\n",
       " 'Yaomomos',\n",
       " '10005',\n",
       " 'Valtteri',\n",
       " 'Deportation',\n",
       " 'Chromebook',\n",
       " 'Honoring',\n",
       " 'tagswitched',\n",
       " 'THCAglucunoride',\n",
       " 'aquiesce',\n",
       " 'JONG',\n",
       " 'bigby',\n",
       " 'BRUISED',\n",
       " 'period109111',\n",
       " 'Panhandling',\n",
       " 'commentaryhttpiimgurcomxFLcPgif',\n",
       " 'borderscapitols',\n",
       " 'Helt',\n",
       " 'dohttpsiimgurcomCxy2rFFmp4',\n",
       " 'DINGA',\n",
       " '2Ga',\n",
       " 'fister',\n",
       " 'REPOSTING',\n",
       " '35seconds',\n",
       " 'Coelho',\n",
       " 'CONTEXTFREE',\n",
       " 'antiislamic',\n",
       " 'Sed',\n",
       " 'Heysel',\n",
       " 'gohttpimgurcomkMoRzKM',\n",
       " 'Pond',\n",
       " 'Spiez',\n",
       " 'kysing',\n",
       " 'UPSET',\n",
       " 'Aubracadabra',\n",
       " 'whil',\n",
       " 'chare',\n",
       " 'rwhat34',\n",
       " 'fivepointed',\n",
       " 'sloggedly',\n",
       " 'Upsets',\n",
       " 'Hormone',\n",
       " 'httpsenwikipediaorgwikiWorldonFirebook',\n",
       " 'Travels',\n",
       " 'BHRF',\n",
       " 'inocentes',\n",
       " 'jmu',\n",
       " 'httpwwwiapforgenfaqsthash054pK7Wedpuf',\n",
       " 'GermanyhttpswwwyoutubecomwatchvkWgUYZAI6L8',\n",
       " 'verdadero',\n",
       " 'americapatriotism',\n",
       " 'Rocksteady',\n",
       " 'DOre',\n",
       " 'thigarette',\n",
       " 'rroasted',\n",
       " 'httpiimgurcom18SbvBPjpg1',\n",
       " '38bwk',\n",
       " '3440x1440100hz',\n",
       " 'topples',\n",
       " 'wealthshaming',\n",
       " 'onceaweek',\n",
       " 'shittards',\n",
       " 'stickspithttpfergusjacksonfileswordpresscom200908hogroast4jpg',\n",
       " '25iNBOMe',\n",
       " 'slangshort',\n",
       " '798a3',\n",
       " 'Recipient',\n",
       " 'Wellstated',\n",
       " 'DISTROPHYYYYYYYYYYYY',\n",
       " 'managerwho',\n",
       " 'DinahDash',\n",
       " 'TacNinjabike',\n",
       " 'Basement',\n",
       " 'RetardedhttpswwwetymonlinecomwordRetardedrefetymonlinecrossreference',\n",
       " 'yeilding',\n",
       " 'uphttpsyoutubehhPdH3wE0Y',\n",
       " 'Instrumentals',\n",
       " 'Stabilize',\n",
       " 'HB3',\n",
       " 'cajun',\n",
       " 'Psyonix',\n",
       " 'pawfice',\n",
       " 'Respawn',\n",
       " 'idplayer',\n",
       " 'mediahttpwwwglobaltimescncontent1067405shtml',\n",
       " 'boneappletea',\n",
       " 'groupname',\n",
       " 'personhttpswwwyoutubecomwatchvWcSgpyJWRY',\n",
       " 'Cocacola',\n",
       " 'httpwwwstoporganharvestingorg',\n",
       " 'Cigs',\n",
       " 'annoied',\n",
       " 'trepan',\n",
       " 'Harbour',\n",
       " 'saree',\n",
       " 'lowI',\n",
       " 'reoccurrence',\n",
       " 'Solidly',\n",
       " 'overhyping',\n",
       " 'gettingmaking',\n",
       " 'courtside',\n",
       " 'Gestures',\n",
       " 'Inquire',\n",
       " 'badevil',\n",
       " 'Renuzshit',\n",
       " '55mph',\n",
       " 'httpswwwbbccouknewsworlduscanada39044403',\n",
       " 'taserface',\n",
       " 'Leprechauny',\n",
       " 'IthttpwwwyoutubecomwatchvEBXU2t4hodo',\n",
       " 'httpswwwgooglecomampwwwindependentcouknewsworldmiddleeastsaudiarabiawomendriverslegalbanmanjailedkingsalmanburncara7973966html3Famp',\n",
       " 'Staterun',\n",
       " 'filteringcleaning',\n",
       " 'maniquien',\n",
       " '2fa',\n",
       " 'samethink',\n",
       " 'quiltblanket',\n",
       " 'maintainance',\n",
       " 'Silverlight',\n",
       " 'standin',\n",
       " 'muchI',\n",
       " 'furstoval',\n",
       " 'industrialisation',\n",
       " 'havehavent',\n",
       " 'worthhttpwwwlesmachinesnantesfrenpracticalinformationpricesindividualprices',\n",
       " 'shalwar',\n",
       " 'reacquired',\n",
       " 'wikipediahttpenwikipediaorgwikiLightsaberTypes',\n",
       " 'Auld',\n",
       " 'httpsenmwiktionaryorgwikisinogram',\n",
       " 'sjgr',\n",
       " 'Scholarships',\n",
       " '4379',\n",
       " 'bugstickets',\n",
       " 'responsibilitiesfamilies',\n",
       " '10x10x10',\n",
       " 'Moby',\n",
       " 'ashttpwwwmerriamwebstercomdictionaryfiancC3A9',\n",
       " 'httpsmhuffpostcomusentry5806972',\n",
       " 'seenhttpsimgurcoma7fIGCuP',\n",
       " 'unvoted',\n",
       " 'storebought',\n",
       " 'Eccept',\n",
       " 'Plemons',\n",
       " 'Nei',\n",
       " 'trollhunters',\n",
       " 'fortunederived',\n",
       " 'detailsa',\n",
       " 'fishd',\n",
       " 'EOD',\n",
       " 'httpwwwquickmemecommeme3tlopl',\n",
       " 'yummmm',\n",
       " 'httpswwwhrworgamericascuba',\n",
       " 'subscreen',\n",
       " 'dMNMNdmdCHILLSACTUALFREESPEECHMds',\n",
       " 'dovey',\n",
       " 'coutries',\n",
       " 'trig',\n",
       " '1315k',\n",
       " 'shapely',\n",
       " 'sens8',\n",
       " 'biar',\n",
       " 'Rhona',\n",
       " 'snakepit',\n",
       " 'hebrajsku',\n",
       " 'Dohttpscdnevbstaticcoms3s3staticimagesenUSmyeventsmanagemodifyorderoptionseventtypeandlanguageselecteventpagelanguagedropdownpng',\n",
       " 'DVJBAHG',\n",
       " 'CPRBLS',\n",
       " 'KAMINARI',\n",
       " 'BENGHAZIECT',\n",
       " 'consolebased',\n",
       " 'ciggs',\n",
       " 'httpwwwsicomnba20150923chrisboshheatraptorsgeorgiatechhealthbloodclotslebronjames',\n",
       " 'Larsons',\n",
       " 'threatsviolencethreats',\n",
       " 'ONeil',\n",
       " 'archage',\n",
       " 'xphobes',\n",
       " 'tenkte',\n",
       " 'introtutorial',\n",
       " 'bitattacked',\n",
       " 'Leonora',\n",
       " 'Supe',\n",
       " 'httpsjakeporterorg',\n",
       " 'rRetiredCartoon',\n",
       " '450mgday',\n",
       " 'Planum',\n",
       " 'Mackenzie',\n",
       " 'rickshaw',\n",
       " 'nonplumber',\n",
       " 'ukgtech',\n",
       " 'vanshe',\n",
       " 'MUNI',\n",
       " 'trevor',\n",
       " 'httpsenmwikipediaorgwikiListoflakesbyareawprovsfla1',\n",
       " 'astroturfer',\n",
       " 'eli',\n",
       " 'ondisturbed',\n",
       " 'STEAK',\n",
       " 'BIRDIE',\n",
       " 'GOPsupporting',\n",
       " 'pocela',\n",
       " 'Ahhhahahahahaha',\n",
       " 'mosthttparstechnicacominformationtechnology201611longrangeprojectilesfornavysnewestshiptooexpensivetoshoot',\n",
       " 'Emptor',\n",
       " 'herefix',\n",
       " 'COSBY',\n",
       " 'MIDORIYA',\n",
       " 'FAMILYS',\n",
       " 'httpsarchiveorgstream441332stipulationforucdavissettlement441332stipulationforucdavissettlementdjvutxt',\n",
       " 'ronmental',\n",
       " 'scanty',\n",
       " 'asthetics',\n",
       " 'rechecks',\n",
       " 'httpswwwgooglecomampampusatodaycomstory93441516clientsafari',\n",
       " 'Driven',\n",
       " 'busnesses',\n",
       " 'httpiimgurcomnawXeDmpng',\n",
       " 'kii',\n",
       " 'Ab',\n",
       " 'Badabababa',\n",
       " 'Infanticide',\n",
       " 'washable',\n",
       " 'Breezango',\n",
       " 'Markman',\n",
       " 'celebritieshttpswwwyoutubecomwatchvXg2vYqjERnE',\n",
       " 'Misreading',\n",
       " 'Munch',\n",
       " '15mpg',\n",
       " 'Rainman',\n",
       " '07m',\n",
       " 'thow',\n",
       " 'disablilites',\n",
       " 'EXTRAORDINARY',\n",
       " 'againDepression',\n",
       " 'USEFUL',\n",
       " 'httpsyoutubeYWZkwuILnst3m22s',\n",
       " 'acctual',\n",
       " 'LGT',\n",
       " 'Hando',\n",
       " 'eloign',\n",
       " 'Garlic',\n",
       " 'baldurs',\n",
       " 'SCREEN',\n",
       " 'rrimjobstevebaiting',\n",
       " 'approachhttpsmbarnesandnoblecompclassicalstudiesforpickstyleguitarvolume1williamleavitt11109739062661966569307stPLAsidBNBADLMarketplaceGoodUsedTextbooksMobileLowsourceIdPLAGoNAdpidtdtve346c2sidGooglemgclidCj0KCQjwoKzsBRC5ARIsAITcwXGXnM3RVzxSYf03qdGmi0XkEIduj0xvKnhaMMufPVWYeJwfME1QFoIaAmogEALwwcB',\n",
       " 'iterate',\n",
       " 'okotoks',\n",
       " 'photogs',\n",
       " 'appetit',\n",
       " 'Mitchel',\n",
       " 'Schoolcraft',\n",
       " 'F100',\n",
       " '9n',\n",
       " 'REAGAN',\n",
       " 'longways',\n",
       " 'httpswwwyoutubecomwatchv6AdDLhPwpp4',\n",
       " 'emigrateimmigrate',\n",
       " 'Baci',\n",
       " 'niggardlyhttpsenwikipediaorgwikiControversiesabouttheword22niggardly22',\n",
       " 'PagChomp',\n",
       " 'Maman',\n",
       " 'Demilitarize',\n",
       " 'photoshttpswwwredditcomrpicscomments6f7yy0itook5pictureswithmydroneandstitchedthemdig94fk',\n",
       " 'suffering',\n",
       " 'siendo',\n",
       " 'communityreliance',\n",
       " 'coughguantanimocoughbiggestinprisonercough',\n",
       " 'Pepperspray',\n",
       " 'CorporateEnterprise',\n",
       " 'rhavearegularwhingeabouthowbadrsportsis',\n",
       " 'uSirTalkALot406',\n",
       " 'Montreat',\n",
       " 'Danggggggggggg',\n",
       " 'victimology',\n",
       " 'Dmitrij',\n",
       " 'editorialhttpsampeconomistcomchina20120204dogsandlocusts',\n",
       " 'voyeurism',\n",
       " 'Witney',\n",
       " 'panucho',\n",
       " 'kunnka',\n",
       " 'statisticshttpspicsmemebirthcontroleffectivenessbirthcrocscontrolcondomspills99991059356png',\n",
       " 'httpsenwikipediaorgwiki2017ConstituentNationalAssembly2018presidentialelections',\n",
       " 'httpsyoutube7WBWT1gg9sI',\n",
       " '1394',\n",
       " 'spraymace',\n",
       " 'StadiumhttpiimgurcomiAZr3Ksjpg',\n",
       " 'shiv',\n",
       " 'Bravissima',\n",
       " 'Wahlbelg',\n",
       " 'Redstripe',\n",
       " 'Michellonfire',\n",
       " '72nd',\n",
       " 'httpswwwyoutubecomwatchvuhscMsBhNhw',\n",
       " 'rGaryJohnson',\n",
       " '2439',\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "throwout_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(comment):\n",
    "    return comment.lower()\n",
    "\n",
    "g2 = series_grams(data['lemma'].map(lower).map(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [im guess, guess you, you buy, buy game, game ...\n",
       "1         [bitcoins fatal, fatal flaw, flaw be, be there...\n",
       "2         [that be, be really, really freak, freak retar...\n",
       "3         [the technology, technology be, be great, grea...\n",
       "4         [well these, these guy, guy do, do get, get ca...\n",
       "                                ...                        \n",
       "799056    [huh no, no wonder, wonder he, he such, such a...\n",
       "799057                        [such a, a great, great game]\n",
       "799058    [it just, just occur, occur to, to me, me ive,...\n",
       "799059    [id say, say nz, nz but, but i, i dont, dont d...\n",
       "799060                                                   []\n",
       "Length: 799061, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>2_gram</th>\n",
       "      <th>3_gram</th>\n",
       "      <th>4_gram</th>\n",
       "      <th>2__gram</th>\n",
       "      <th>lemma</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>count</th>\n",
       "      <th>slurred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>CouchPotatoFamine</td>\n",
       "      <td>Truly, that is a faggot of epic proportions.</td>\n",
       "      <td>24k1eq</td>\n",
       "      <td>ch7vf3d</td>\n",
       "      <td>funny</td>\n",
       "      <td>['truly that', 'that is', 'is a', 'a faggot', ...</td>\n",
       "      <td>['truly that is', 'that is a', 'is a faggot', ...</td>\n",
       "      <td>['truly that is a', 'that is a faggot', 'is a ...</td>\n",
       "      <td>[truly that, that is, is a, a faggot, faggot o...</td>\n",
       "      <td>Truly that be a faggot of epic proportion.</td>\n",
       "      <td>truly that be a faggot of epic proportion.</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>CouchPotatoFamine</td>\n",
       "      <td>Fag</td>\n",
       "      <td>2z9n20</td>\n",
       "      <td>cpheq1a</td>\n",
       "      <td>classiccars</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Fag.</td>\n",
       "      <td>fag.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10956</th>\n",
       "      <td>omnipedia</td>\n",
       "      <td>So you prefer lip service from a fag hater ove...</td>\n",
       "      <td>4mifnp</td>\n",
       "      <td>d3wqy50</td>\n",
       "      <td>lolgrindr</td>\n",
       "      <td>['so you', 'you prefer', 'prefer lip', 'lip se...</td>\n",
       "      <td>['so you prefer', 'you prefer lip', 'prefer li...</td>\n",
       "      <td>['so you prefer lip', 'you prefer lip service'...</td>\n",
       "      <td>[so you, you prefer, prefer lip, lip service, ...</td>\n",
       "      <td>So you prefer lip service from a fag hater ove...</td>\n",
       "      <td>so you prefer lip service from a fag hater ove...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11296</th>\n",
       "      <td>omnipedia</td>\n",
       "      <td>If I was full of shit, you could muster someth...</td>\n",
       "      <td>5phool</td>\n",
       "      <td>dcrsos5</td>\n",
       "      <td>pinkfloyd</td>\n",
       "      <td>['if i', 'i was', 'was full', 'full of', 'of s...</td>\n",
       "      <td>['if i was', 'i was full', 'was full of', 'ful...</td>\n",
       "      <td>['if i was full', 'i was full of', 'was full o...</td>\n",
       "      <td>[if i, i was, was full, full of, of shit, shit...</td>\n",
       "      <td>If I be full of shit you could muster somethin...</td>\n",
       "      <td>if i be full of shit you could muster somethin...</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11589</th>\n",
       "      <td>omnipedia</td>\n",
       "      <td>If I was full of shit, you could muster someth...</td>\n",
       "      <td>5phool</td>\n",
       "      <td>dcrme4q</td>\n",
       "      <td>pinkfloyd</td>\n",
       "      <td>['if i', 'i was', 'was full', 'full of', 'of s...</td>\n",
       "      <td>['if i was', 'i was full', 'was full of', 'ful...</td>\n",
       "      <td>['if i was full', 'i was full of', 'was full o...</td>\n",
       "      <td>[if i, i was, was full, full of, of shit, shit...</td>\n",
       "      <td>If I be full of shit you could muster somethin...</td>\n",
       "      <td>if i be full of shit you could muster somethin...</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782029</th>\n",
       "      <td>chrispdx</td>\n",
       "      <td>BREAKING NEWS: OP NOT A FAGGOT. FILM AT 11</td>\n",
       "      <td>1go7rt</td>\n",
       "      <td>camhkxm</td>\n",
       "      <td>thick</td>\n",
       "      <td>['breaking news', 'news op', 'op not', 'not a'...</td>\n",
       "      <td>['breaking news op', 'news op not', 'op not a'...</td>\n",
       "      <td>['breaking news op not', 'news op not a', 'op ...</td>\n",
       "      <td>[breaking news, news op, op not, not a, a fagg...</td>\n",
       "      <td>BREAKING NEWS OP NOT A FAGGOT. FILM AT 11.</td>\n",
       "      <td>breaking news op not a faggot. film at 11.</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782227</th>\n",
       "      <td>chrispdx</td>\n",
       "      <td>My father, .\\nwho grew up in more racist times...</td>\n",
       "      <td>27nrbc</td>\n",
       "      <td>ci2sjt1</td>\n",
       "      <td>videos</td>\n",
       "      <td>['my father', 'father who', 'who grew', 'grew ...</td>\n",
       "      <td>['my father who', 'father who grew', 'who grew...</td>\n",
       "      <td>['my father who grew', 'father who grew up', '...</td>\n",
       "      <td>[my father, father who, who grew, grew up, up ...</td>\n",
       "      <td>My father. who grow up in more racist time tol...</td>\n",
       "      <td>my father. who grow up in more racist time tol...</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782296</th>\n",
       "      <td>chrispdx</td>\n",
       "      <td>The average Republican laughs in your face ove...</td>\n",
       "      <td>iqud1</td>\n",
       "      <td>c25wt7z</td>\n",
       "      <td>politics</td>\n",
       "      <td>['the average', 'average republican', 'republi...</td>\n",
       "      <td>['the average republican', 'average republican...</td>\n",
       "      <td>['the average republican laughs', 'average rep...</td>\n",
       "      <td>[the average, average republican, republican l...</td>\n",
       "      <td>The average Republican laugh in your face over...</td>\n",
       "      <td>the average republican laugh in your face over...</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782370</th>\n",
       "      <td>chrispdx</td>\n",
       "      <td>While I've often remarked on the Ivory Tower w...</td>\n",
       "      <td>11n1qd</td>\n",
       "      <td>c6nvl96</td>\n",
       "      <td>PoliticalDiscussion</td>\n",
       "      <td>['while ive', 'ive often', 'often remarked', '...</td>\n",
       "      <td>['while ive often', 'ive often remarked', 'oft...</td>\n",
       "      <td>['while ive often remarked', 'ive often remark...</td>\n",
       "      <td>[while ive, ive often, often remarked, remarke...</td>\n",
       "      <td>While Ive often remark on the Ivory Tower we R...</td>\n",
       "      <td>while ive often remark on the ivory tower we r...</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791749</th>\n",
       "      <td>tool_of_justice</td>\n",
       "      <td>Mah nigga</td>\n",
       "      <td>c3yu75</td>\n",
       "      <td>eruiy7d</td>\n",
       "      <td>india</td>\n",
       "      <td>['mah nigga']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mah nigga]</td>\n",
       "      <td>Mah nigga.</td>\n",
       "      <td>mah nigga.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                               body  \\\n",
       "6216    CouchPotatoFamine       Truly, that is a faggot of epic proportions.   \n",
       "6489    CouchPotatoFamine                                                Fag   \n",
       "10956           omnipedia  So you prefer lip service from a fag hater ove...   \n",
       "11296           omnipedia  If I was full of shit, you could muster someth...   \n",
       "11589           omnipedia  If I was full of shit, you could muster someth...   \n",
       "...                   ...                                                ...   \n",
       "782029           chrispdx         BREAKING NEWS: OP NOT A FAGGOT. FILM AT 11   \n",
       "782227           chrispdx  My father, .\\nwho grew up in more racist times...   \n",
       "782296           chrispdx  The average Republican laughs in your face ove...   \n",
       "782370           chrispdx  While I've often remarked on the Ivory Tower w...   \n",
       "791749    tool_of_justice                                          Mah nigga   \n",
       "\n",
       "        sub_id comment_id            subreddit  \\\n",
       "6216    24k1eq    ch7vf3d                funny   \n",
       "6489    2z9n20    cpheq1a          classiccars   \n",
       "10956   4mifnp    d3wqy50            lolgrindr   \n",
       "11296   5phool    dcrsos5            pinkfloyd   \n",
       "11589   5phool    dcrme4q            pinkfloyd   \n",
       "...        ...        ...                  ...   \n",
       "782029  1go7rt    camhkxm                thick   \n",
       "782227  27nrbc    ci2sjt1               videos   \n",
       "782296   iqud1    c25wt7z             politics   \n",
       "782370  11n1qd    c6nvl96  PoliticalDiscussion   \n",
       "791749  c3yu75    eruiy7d                india   \n",
       "\n",
       "                                                   2_gram  \\\n",
       "6216    ['truly that', 'that is', 'is a', 'a faggot', ...   \n",
       "6489                                                   []   \n",
       "10956   ['so you', 'you prefer', 'prefer lip', 'lip se...   \n",
       "11296   ['if i', 'i was', 'was full', 'full of', 'of s...   \n",
       "11589   ['if i', 'i was', 'was full', 'full of', 'of s...   \n",
       "...                                                   ...   \n",
       "782029  ['breaking news', 'news op', 'op not', 'not a'...   \n",
       "782227  ['my father', 'father who', 'who grew', 'grew ...   \n",
       "782296  ['the average', 'average republican', 'republi...   \n",
       "782370  ['while ive', 'ive often', 'often remarked', '...   \n",
       "791749                                      ['mah nigga']   \n",
       "\n",
       "                                                   3_gram  \\\n",
       "6216    ['truly that is', 'that is a', 'is a faggot', ...   \n",
       "6489                                                   []   \n",
       "10956   ['so you prefer', 'you prefer lip', 'prefer li...   \n",
       "11296   ['if i was', 'i was full', 'was full of', 'ful...   \n",
       "11589   ['if i was', 'i was full', 'was full of', 'ful...   \n",
       "...                                                   ...   \n",
       "782029  ['breaking news op', 'news op not', 'op not a'...   \n",
       "782227  ['my father who', 'father who grew', 'who grew...   \n",
       "782296  ['the average republican', 'average republican...   \n",
       "782370  ['while ive often', 'ive often remarked', 'oft...   \n",
       "791749                                                 []   \n",
       "\n",
       "                                                   4_gram  \\\n",
       "6216    ['truly that is a', 'that is a faggot', 'is a ...   \n",
       "6489                                                   []   \n",
       "10956   ['so you prefer lip', 'you prefer lip service'...   \n",
       "11296   ['if i was full', 'i was full of', 'was full o...   \n",
       "11589   ['if i was full', 'i was full of', 'was full o...   \n",
       "...                                                   ...   \n",
       "782029  ['breaking news op not', 'news op not a', 'op ...   \n",
       "782227  ['my father who grew', 'father who grew up', '...   \n",
       "782296  ['the average republican laughs', 'average rep...   \n",
       "782370  ['while ive often remarked', 'ive often remark...   \n",
       "791749                                                 []   \n",
       "\n",
       "                                                  2__gram  \\\n",
       "6216    [truly that, that is, is a, a faggot, faggot o...   \n",
       "6489                                                   []   \n",
       "10956   [so you, you prefer, prefer lip, lip service, ...   \n",
       "11296   [if i, i was, was full, full of, of shit, shit...   \n",
       "11589   [if i, i was, was full, full of, of shit, shit...   \n",
       "...                                                   ...   \n",
       "782029  [breaking news, news op, op not, not a, a fagg...   \n",
       "782227  [my father, father who, who grew, grew up, up ...   \n",
       "782296  [the average, average republican, republican l...   \n",
       "782370  [while ive, ive often, often remarked, remarke...   \n",
       "791749                                        [mah nigga]   \n",
       "\n",
       "                                                    lemma  \\\n",
       "6216           Truly that be a faggot of epic proportion.   \n",
       "6489                                                 Fag.   \n",
       "10956   So you prefer lip service from a fag hater ove...   \n",
       "11296   If I be full of shit you could muster somethin...   \n",
       "11589   If I be full of shit you could muster somethin...   \n",
       "...                                                   ...   \n",
       "782029         BREAKING NEWS OP NOT A FAGGOT. FILM AT 11.   \n",
       "782227  My father. who grow up in more racist time tol...   \n",
       "782296  The average Republican laugh in your face over...   \n",
       "782370  While Ive often remark on the Ivory Tower we R...   \n",
       "791749                                         Mah nigga.   \n",
       "\n",
       "                                                lowercase  count  slurred  \n",
       "6216           truly that be a faggot of epic proportion.      8        1  \n",
       "6489                                                 fag.      1        1  \n",
       "10956   so you prefer lip service from a fag hater ove...     24        1  \n",
       "11296   if i be full of shit you could muster somethin...     67        1  \n",
       "11589   if i be full of shit you could muster somethin...     67        1  \n",
       "...                                                   ...    ...      ...  \n",
       "782029         breaking news op not a faggot. film at 11.      9        1  \n",
       "782227  my father. who grow up in more racist time tol...     90        1  \n",
       "782296  the average republican laugh in your face over...     62        1  \n",
       "782370  while ive often remark on the ivory tower we r...     98        1  \n",
       "791749                                         mah nigga.      2        1  \n",
       "\n",
       "[158 rows x 13 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "please_work[please_work['slurred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/justin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = [(author,count) for author,count in Counter(please_work['author'].values).items()]\n",
    "ct.sort(key=lambda x:x[1])\n",
    "a_set = set([author for author,count in ct[::-1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "please_work = please_work.loc[with_author['author'].isin(a_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {'J':wordnet.ADJ,'N':wordnet.NOUN,'V':wordnet.VERB,\n",
    "               'R':wordnet.ADV}\n",
    "    return tag_dict.get(tag,wordnet.NOUN)\n",
    "def lemmatize_sentence(sentence):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    return ' '.join([\n",
    "        lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in\n",
    "        nltk.word_tokenize(sentence)\n",
    "    ]) + '.'\n",
    "def process_comment(comment):\n",
    "    out = []\n",
    "    for sentence in TextBlob(clean_text(comment)).sentences:\n",
    "        out.append(' '.join(w.lemmatize(get_wordnet_pos(w)) for w in sentence.words))\n",
    "    return '. '.join(out) + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These be a test. This be only a test. This be not an actual emergency.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_comment('These are a tests.  This is only a test.  This is not an actual emergency.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb=MultiLabelBinarizer(sparse_output=True)\n",
    "gram_2 = mlb.fit_transform(subset['2-gram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "please_work['slurred2'] = please_work['lowercase'].map(slurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_author = data[data['author'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('extra_storage/lemmatized_comments.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im guess you buy game on steam gog origin uplay whats wrong with windows store.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lowercase'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'] = data['lowercase'].map(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 55706),\n",
       " (4, 36638),\n",
       " (5, 36273),\n",
       " (6, 35408),\n",
       " (3, 33566),\n",
       " (7, 33525),\n",
       " (8, 31138),\n",
       " (2, 29337),\n",
       " (9, 28684),\n",
       " (10, 26538),\n",
       " (11, 24446),\n",
       " (12, 22673),\n",
       " (13, 21247),\n",
       " (14, 19016),\n",
       " (15, 17778),\n",
       " (16, 16690),\n",
       " (17, 15328),\n",
       " (18, 14577),\n",
       " (19, 13515),\n",
       " (20, 12665),\n",
       " (21, 11795),\n",
       " (22, 10994),\n",
       " (23, 10283),\n",
       " (24, 9692),\n",
       " (25, 9073),\n",
       " (26, 8447),\n",
       " (27, 8165),\n",
       " (28, 7703),\n",
       " (29, 7181),\n",
       " (30, 6745),\n",
       " (31, 6304),\n",
       " (32, 6084),\n",
       " (33, 5782),\n",
       " (34, 5546),\n",
       " (35, 5351),\n",
       " (36, 4986),\n",
       " (37, 4808),\n",
       " (38, 4514),\n",
       " (39, 4485),\n",
       " (40, 4260),\n",
       " (41, 3983),\n",
       " (42, 3881),\n",
       " (43, 3628),\n",
       " (44, 3539),\n",
       " (45, 3343),\n",
       " (46, 3226),\n",
       " (47, 3067),\n",
       " (49, 2857),\n",
       " (48, 2847),\n",
       " (50, 2686),\n",
       " (51, 2667),\n",
       " (53, 2455),\n",
       " (52, 2418),\n",
       " (54, 2408),\n",
       " (55, 2382),\n",
       " (56, 2190),\n",
       " (58, 2090),\n",
       " (57, 2087),\n",
       " (61, 1966),\n",
       " (59, 1963),\n",
       " (60, 1890),\n",
       " (62, 1829),\n",
       " (63, 1751),\n",
       " (64, 1733),\n",
       " (65, 1583),\n",
       " (68, 1579),\n",
       " (66, 1544),\n",
       " (67, 1522),\n",
       " (69, 1457),\n",
       " (70, 1438),\n",
       " (71, 1352),\n",
       " (72, 1337),\n",
       " (73, 1301),\n",
       " (75, 1233),\n",
       " (74, 1194),\n",
       " (76, 1150),\n",
       " (78, 1105),\n",
       " (77, 1101),\n",
       " (79, 1094),\n",
       " (80, 1049),\n",
       " (82, 994),\n",
       " (81, 955),\n",
       " (83, 943),\n",
       " (86, 933),\n",
       " (84, 908),\n",
       " (85, 903),\n",
       " (87, 876),\n",
       " (90, 820),\n",
       " (88, 791),\n",
       " (92, 770),\n",
       " (91, 757),\n",
       " (89, 751),\n",
       " (93, 740),\n",
       " (95, 697),\n",
       " (94, 682),\n",
       " (101, 672),\n",
       " (97, 669),\n",
       " (98, 665),\n",
       " (99, 660),\n",
       " (96, 625),\n",
       " (100, 597),\n",
       " (102, 554),\n",
       " (104, 544),\n",
       " (103, 540),\n",
       " (105, 539),\n",
       " (106, 524),\n",
       " (108, 494),\n",
       " (109, 493),\n",
       " (107, 492),\n",
       " (110, 475),\n",
       " (111, 471),\n",
       " (113, 461),\n",
       " (112, 448),\n",
       " (117, 428),\n",
       " (114, 421),\n",
       " (115, 415),\n",
       " (116, 412),\n",
       " (119, 405),\n",
       " (123, 398),\n",
       " (118, 381),\n",
       " (121, 375),\n",
       " (120, 373),\n",
       " (122, 365),\n",
       " (124, 361),\n",
       " (129, 351),\n",
       " (125, 349),\n",
       " (126, 338),\n",
       " (132, 331),\n",
       " (128, 315),\n",
       " (134, 308),\n",
       " (130, 308),\n",
       " (127, 305),\n",
       " (131, 291),\n",
       " (135, 282),\n",
       " (136, 277),\n",
       " (139, 267),\n",
       " (138, 267),\n",
       " (133, 266),\n",
       " (137, 261),\n",
       " (143, 261),\n",
       " (141, 253),\n",
       " (145, 250),\n",
       " (140, 243),\n",
       " (142, 232),\n",
       " (146, 216),\n",
       " (147, 214),\n",
       " (148, 213),\n",
       " (144, 213),\n",
       " (151, 211),\n",
       " (150, 200),\n",
       " (155, 198),\n",
       " (153, 197),\n",
       " (156, 196),\n",
       " (149, 188),\n",
       " (161, 187),\n",
       " (154, 187),\n",
       " (160, 187),\n",
       " (152, 187),\n",
       " (162, 184),\n",
       " (159, 171),\n",
       " (166, 170),\n",
       " (164, 170),\n",
       " (158, 168),\n",
       " (157, 167),\n",
       " (165, 164),\n",
       " (168, 161),\n",
       " (163, 154),\n",
       " (171, 148),\n",
       " (170, 144),\n",
       " (173, 141),\n",
       " (176, 141),\n",
       " (169, 140),\n",
       " (174, 134),\n",
       " (167, 133),\n",
       " (177, 132),\n",
       " (186, 130),\n",
       " (179, 127),\n",
       " (172, 127),\n",
       " (189, 125),\n",
       " (175, 125),\n",
       " (178, 123),\n",
       " (181, 123),\n",
       " (188, 122),\n",
       " (180, 118),\n",
       " (183, 118),\n",
       " (182, 117),\n",
       " (190, 114),\n",
       " (187, 111),\n",
       " (185, 109),\n",
       " (184, 104),\n",
       " (191, 103),\n",
       " (199, 100),\n",
       " (192, 96),\n",
       " (196, 96),\n",
       " (200, 94),\n",
       " (193, 93),\n",
       " (202, 90),\n",
       " (198, 90),\n",
       " (194, 90),\n",
       " (208, 87),\n",
       " (201, 86),\n",
       " (205, 84),\n",
       " (211, 83),\n",
       " (214, 75),\n",
       " (216, 75),\n",
       " (195, 75),\n",
       " (209, 74),\n",
       " (197, 74),\n",
       " (212, 73),\n",
       " (218, 72),\n",
       " (217, 72),\n",
       " (204, 72),\n",
       " (207, 72),\n",
       " (203, 72),\n",
       " (210, 71),\n",
       " (215, 68),\n",
       " (225, 66),\n",
       " (220, 65),\n",
       " (235, 62),\n",
       " (206, 62),\n",
       " (219, 62),\n",
       " (236, 62),\n",
       " (221, 62),\n",
       " (224, 61),\n",
       " (231, 59),\n",
       " (223, 59),\n",
       " (233, 59),\n",
       " (213, 58),\n",
       " (241, 57),\n",
       " (245, 56),\n",
       " (226, 55),\n",
       " (222, 55),\n",
       " (242, 54),\n",
       " (232, 54),\n",
       " (239, 52),\n",
       " (240, 52),\n",
       " (234, 51),\n",
       " (247, 50),\n",
       " (227, 49),\n",
       " (230, 49),\n",
       " (228, 48),\n",
       " (255, 48),\n",
       " (253, 48),\n",
       " (249, 48),\n",
       " (238, 48),\n",
       " (237, 48),\n",
       " (252, 47),\n",
       " (243, 47),\n",
       " (248, 46),\n",
       " (266, 46),\n",
       " (250, 45),\n",
       " (259, 44),\n",
       " (258, 43),\n",
       " (251, 42),\n",
       " (270, 41),\n",
       " (273, 41),\n",
       " (229, 41),\n",
       " (275, 40),\n",
       " (256, 40),\n",
       " (254, 40),\n",
       " (269, 39),\n",
       " (262, 38),\n",
       " (257, 37),\n",
       " (268, 37),\n",
       " (280, 36),\n",
       " (263, 36),\n",
       " (246, 35),\n",
       " (287, 35),\n",
       " (267, 35),\n",
       " (272, 34),\n",
       " (285, 34),\n",
       " (274, 34),\n",
       " (276, 33),\n",
       " (295, 32),\n",
       " (277, 32),\n",
       " (244, 32),\n",
       " (264, 31),\n",
       " (265, 31),\n",
       " (281, 31),\n",
       " (286, 30),\n",
       " (289, 30),\n",
       " (293, 29),\n",
       " (260, 28),\n",
       " (283, 28),\n",
       " (288, 27),\n",
       " (279, 27),\n",
       " (333, 27),\n",
       " (307, 27),\n",
       " (291, 27),\n",
       " (290, 27),\n",
       " (271, 27),\n",
       " (311, 27),\n",
       " (294, 27),\n",
       " (314, 26),\n",
       " (305, 26),\n",
       " (278, 26),\n",
       " (301, 25),\n",
       " (292, 25),\n",
       " (302, 25),\n",
       " (284, 25),\n",
       " (329, 25),\n",
       " (304, 25),\n",
       " (327, 24),\n",
       " (308, 24),\n",
       " (297, 24),\n",
       " (298, 23),\n",
       " (261, 23),\n",
       " (299, 23),\n",
       " (310, 23),\n",
       " (313, 22),\n",
       " (317, 22),\n",
       " (303, 22),\n",
       " (296, 22),\n",
       " (319, 22),\n",
       " (309, 22),\n",
       " (328, 21),\n",
       " (300, 21),\n",
       " (306, 21),\n",
       " (312, 21),\n",
       " (322, 20),\n",
       " (339, 20),\n",
       " (354, 19),\n",
       " (324, 19),\n",
       " (282, 19),\n",
       " (330, 19),\n",
       " (347, 19),\n",
       " (315, 19),\n",
       " (335, 19),\n",
       " (321, 19),\n",
       " (358, 18),\n",
       " (353, 18),\n",
       " (326, 18),\n",
       " (337, 18),\n",
       " (316, 18),\n",
       " (332, 17),\n",
       " (331, 17),\n",
       " (350, 17),\n",
       " (364, 17),\n",
       " (342, 17),\n",
       " (318, 17),\n",
       " (323, 16),\n",
       " (344, 15),\n",
       " (334, 15),\n",
       " (418, 15),\n",
       " (320, 15),\n",
       " (369, 15),\n",
       " (341, 15),\n",
       " (352, 15),\n",
       " (338, 14),\n",
       " (371, 14),\n",
       " (380, 14),\n",
       " (325, 14),\n",
       " (356, 14),\n",
       " (361, 14),\n",
       " (346, 13),\n",
       " (378, 13),\n",
       " (376, 13),\n",
       " (375, 13),\n",
       " (383, 13),\n",
       " (414, 13),\n",
       " (366, 13),\n",
       " (389, 13),\n",
       " (391, 13),\n",
       " (336, 13),\n",
       " (400, 13),\n",
       " (351, 13),\n",
       " (405, 13),\n",
       " (340, 13),\n",
       " (442, 13),\n",
       " (373, 13),\n",
       " (362, 12),\n",
       " (473, 12),\n",
       " (394, 12),\n",
       " (385, 12),\n",
       " (365, 12),\n",
       " (349, 12),\n",
       " (367, 12),\n",
       " (345, 12),\n",
       " (384, 12),\n",
       " (359, 11),\n",
       " (363, 11),\n",
       " (402, 11),\n",
       " (382, 11),\n",
       " (360, 11),\n",
       " (409, 10),\n",
       " (396, 10),\n",
       " (423, 10),\n",
       " (372, 10),\n",
       " (348, 10),\n",
       " (386, 10),\n",
       " (398, 10),\n",
       " (417, 10),\n",
       " (388, 10),\n",
       " (433, 10),\n",
       " (357, 10),\n",
       " (377, 9),\n",
       " (465, 9),\n",
       " (408, 9),\n",
       " (716, 9),\n",
       " (451, 9),\n",
       " (401, 9),\n",
       " (397, 9),\n",
       " (403, 9),\n",
       " (392, 9),\n",
       " (432, 9),\n",
       " (428, 9),\n",
       " (416, 9),\n",
       " (390, 9),\n",
       " (412, 9),\n",
       " (399, 9),\n",
       " (355, 9),\n",
       " (434, 9),\n",
       " (387, 8),\n",
       " (343, 8),\n",
       " (368, 8),\n",
       " (410, 8),\n",
       " (571, 8),\n",
       " (643, 8),\n",
       " (406, 8),\n",
       " (437, 8),\n",
       " (536, 7),\n",
       " (370, 7),\n",
       " (566, 7),\n",
       " (445, 7),\n",
       " (429, 7),\n",
       " (379, 7),\n",
       " (440, 7),\n",
       " (441, 7),\n",
       " (484, 7),\n",
       " (535, 7),\n",
       " (447, 7),\n",
       " (395, 7),\n",
       " (438, 7),\n",
       " (478, 7),\n",
       " (374, 7),\n",
       " (497, 6),\n",
       " (425, 6),\n",
       " (546, 6),\n",
       " (486, 6),\n",
       " (468, 6),\n",
       " (466, 6),\n",
       " (411, 6),\n",
       " (487, 6),\n",
       " (431, 6),\n",
       " (421, 6),\n",
       " (474, 6),\n",
       " (512, 6),\n",
       " (492, 6),\n",
       " (413, 6),\n",
       " (427, 6),\n",
       " (444, 6),\n",
       " (443, 6),\n",
       " (522, 6),\n",
       " (381, 6),\n",
       " (415, 6),\n",
       " (482, 6),\n",
       " (460, 6),\n",
       " (532, 6),\n",
       " (404, 6),\n",
       " (483, 6),\n",
       " (554, 6),\n",
       " (540, 6),\n",
       " (603, 5),\n",
       " (424, 5),\n",
       " (448, 5),\n",
       " (393, 5),\n",
       " (610, 5),\n",
       " (493, 5),\n",
       " (458, 5),\n",
       " (724, 5),\n",
       " (485, 5),\n",
       " (583, 5),\n",
       " (480, 5),\n",
       " (426, 5),\n",
       " (407, 5),\n",
       " (639, 5),\n",
       " (521, 5),\n",
       " (436, 5),\n",
       " (449, 5),\n",
       " (435, 5),\n",
       " (469, 5),\n",
       " (461, 5),\n",
       " (453, 5),\n",
       " (472, 5),\n",
       " (507, 4),\n",
       " (886, 4),\n",
       " (481, 4),\n",
       " (577, 4),\n",
       " (462, 4),\n",
       " (459, 4),\n",
       " (800, 4),\n",
       " (650, 4),\n",
       " (475, 4),\n",
       " (701, 4),\n",
       " (479, 4),\n",
       " (709, 4),\n",
       " (517, 4),\n",
       " (611, 4),\n",
       " (723, 4),\n",
       " (547, 4),\n",
       " (686, 4),\n",
       " (605, 4),\n",
       " (525, 4),\n",
       " (515, 4),\n",
       " (630, 4),\n",
       " (815, 4),\n",
       " (607, 4),\n",
       " (506, 4),\n",
       " (498, 4),\n",
       " (456, 4),\n",
       " (680, 4),\n",
       " (575, 4),\n",
       " (629, 4),\n",
       " (419, 4),\n",
       " (488, 3),\n",
       " (504, 3),\n",
       " (602, 3),\n",
       " (645, 3),\n",
       " (494, 3),\n",
       " (446, 3),\n",
       " (597, 3),\n",
       " (710, 3),\n",
       " (600, 3),\n",
       " (567, 3),\n",
       " (508, 3),\n",
       " (519, 3),\n",
       " (529, 3),\n",
       " (520, 3),\n",
       " (714, 3),\n",
       " (734, 3),\n",
       " (682, 3),\n",
       " (552, 3),\n",
       " (975, 3),\n",
       " (541, 3),\n",
       " (636, 3),\n",
       " (470, 3),\n",
       " (604, 3),\n",
       " (705, 3),\n",
       " (562, 3),\n",
       " (491, 3),\n",
       " (576, 3),\n",
       " (657, 3),\n",
       " (661, 3),\n",
       " (743, 3),\n",
       " (580, 3),\n",
       " (725, 3),\n",
       " (579, 3),\n",
       " (1538, 3),\n",
       " (642, 3),\n",
       " (596, 3),\n",
       " (513, 3),\n",
       " (651, 3),\n",
       " (548, 3),\n",
       " (542, 3),\n",
       " (527, 3),\n",
       " (489, 3),\n",
       " (457, 3),\n",
       " (544, 3),\n",
       " (455, 3),\n",
       " (697, 3),\n",
       " (570, 3),\n",
       " (537, 3),\n",
       " (592, 3),\n",
       " (573, 3),\n",
       " (556, 3),\n",
       " (551, 3),\n",
       " (591, 3),\n",
       " (555, 3),\n",
       " (518, 3),\n",
       " (613, 3),\n",
       " (516, 3),\n",
       " (509, 3),\n",
       " (616, 3),\n",
       " (557, 3),\n",
       " (524, 3),\n",
       " (727, 3),\n",
       " (422, 3),\n",
       " (530, 3),\n",
       " (471, 3),\n",
       " (1195, 2),\n",
       " (820, 2),\n",
       " (847, 2),\n",
       " (699, 2),\n",
       " (824, 2),\n",
       " (712, 2),\n",
       " (731, 2),\n",
       " (1198, 2),\n",
       " (935, 2),\n",
       " (868, 2),\n",
       " (558, 2),\n",
       " (510, 2),\n",
       " (981, 2),\n",
       " (717, 2),\n",
       " (543, 2),\n",
       " (685, 2),\n",
       " (618, 2),\n",
       " (464, 2),\n",
       " (476, 2),\n",
       " (539, 2),\n",
       " (672, 2),\n",
       " (993, 2),\n",
       " (621, 2),\n",
       " (761, 2),\n",
       " (744, 2),\n",
       " (647, 2),\n",
       " (590, 2),\n",
       " (959, 2),\n",
       " (614, 2),\n",
       " (467, 2),\n",
       " (1351, 2),\n",
       " (1360, 2),\n",
       " (545, 2),\n",
       " (622, 2),\n",
       " (986, 2),\n",
       " (1694, 2),\n",
       " (748, 2),\n",
       " (864, 2),\n",
       " (736, 2),\n",
       " (702, 2),\n",
       " (669, 2),\n",
       " (582, 2),\n",
       " (615, 2),\n",
       " (538, 2),\n",
       " (793, 2),\n",
       " (593, 2),\n",
       " (430, 2),\n",
       " (534, 2),\n",
       " (719, 2),\n",
       " (673, 2),\n",
       " (681, 2),\n",
       " (691, 2),\n",
       " (848, 2),\n",
       " (750, 2),\n",
       " (511, 2),\n",
       " (574, 2),\n",
       " (860, 2),\n",
       " (856, 2),\n",
       " (810, 2),\n",
       " (477, 2),\n",
       " (948, 2),\n",
       " (568, 2),\n",
       " (985, 2),\n",
       " (1078, 2),\n",
       " (654, 2),\n",
       " (693, 2),\n",
       " (745, 2),\n",
       " (632, 2),\n",
       " (671, 2),\n",
       " (687, 2),\n",
       " (707, 2),\n",
       " (834, 2),\n",
       " (840, 2),\n",
       " (594, 2),\n",
       " (721, 2),\n",
       " (452, 2),\n",
       " (439, 2),\n",
       " (606, 2),\n",
       " (633, 2),\n",
       " (637, 2),\n",
       " (625, 2),\n",
       " (454, 2),\n",
       " (638, 2),\n",
       " (936, 2),\n",
       " (560, 2),\n",
       " (612, 2),\n",
       " (689, 2),\n",
       " (514, 2),\n",
       " (742, 2),\n",
       " (526, 2),\n",
       " (690, 2),\n",
       " (499, 2),\n",
       " (420, 2),\n",
       " (501, 2),\n",
       " (585, 2),\n",
       " (587, 2),\n",
       " (842, 2),\n",
       " (1396, 1),\n",
       " (814, 1),\n",
       " (1066, 1),\n",
       " (1215, 1),\n",
       " (668, 1),\n",
       " (664, 1),\n",
       " (564, 1),\n",
       " (851, 1),\n",
       " (1340, 1),\n",
       " (903, 1),\n",
       " (921, 1),\n",
       " (754, 1),\n",
       " (1080, 1),\n",
       " (1110, 1),\n",
       " (930, 1),\n",
       " (588, 1),\n",
       " (823, 1),\n",
       " (741, 1),\n",
       " (1089, 1),\n",
       " (772, 1),\n",
       " (881, 1),\n",
       " (844, 1),\n",
       " (826, 1),\n",
       " (999, 1),\n",
       " (569, 1),\n",
       " (1104, 1),\n",
       " (678, 1),\n",
       " (1734, 1),\n",
       " (1009, 1),\n",
       " (1231, 1),\n",
       " (565, 1),\n",
       " (1330, 1),\n",
       " (1256, 1),\n",
       " (1281, 1),\n",
       " (1129, 1),\n",
       " (550, 1),\n",
       " (666, 1),\n",
       " (756, 1),\n",
       " (976, 1),\n",
       " (972, 1),\n",
       " (495, 1),\n",
       " (854, 1),\n",
       " (1168, 1),\n",
       " (1025, 1),\n",
       " (895, 1),\n",
       " (962, 1),\n",
       " (1169, 1),\n",
       " (786, 1),\n",
       " (873, 1),\n",
       " (735, 1),\n",
       " (677, 1),\n",
       " (1160, 1),\n",
       " (973, 1),\n",
       " (595, 1),\n",
       " (1044, 1),\n",
       " (533, 1),\n",
       " (496, 1),\n",
       " (906, 1),\n",
       " (1589, 1),\n",
       " (760, 1),\n",
       " (867, 1),\n",
       " (732, 1),\n",
       " (912, 1),\n",
       " (624, 1),\n",
       " (1416, 1),\n",
       " (1093, 1),\n",
       " (762, 1),\n",
       " (641, 1),\n",
       " (623, 1),\n",
       " (1115, 1),\n",
       " (747, 1),\n",
       " (764, 1),\n",
       " (1145, 1),\n",
       " (1190, 1),\n",
       " (1430, 1),\n",
       " (653, 1),\n",
       " (955, 1),\n",
       " (944, 1),\n",
       " (1304, 1),\n",
       " (563, 1),\n",
       " (1292, 1),\n",
       " (1173, 1),\n",
       " (1039, 1),\n",
       " (1664, 1),\n",
       " (866, 1),\n",
       " (904, 1),\n",
       " (1509, 1),\n",
       " (1018, 1),\n",
       " (813, 1),\n",
       " (1369, 1),\n",
       " (853, 1),\n",
       " (963, 1),\n",
       " (740, 1),\n",
       " (933, 1),\n",
       " (909, 1),\n",
       " (925, 1),\n",
       " (983, 1),\n",
       " (788, 1),\n",
       " (1477, 1),\n",
       " (757, 1),\n",
       " (763, 1),\n",
       " (1013, 1),\n",
       " (608, 1),\n",
       " (1133, 1),\n",
       " (1155, 1),\n",
       " (658, 1),\n",
       " (1010, 1),\n",
       " (1552, 1),\n",
       " (774, 1),\n",
       " (640, 1),\n",
       " (1764, 1),\n",
       " (1031, 1),\n",
       " (1200, 1),\n",
       " (1702, 1),\n",
       " (1497, 1),\n",
       " (905, 1),\n",
       " (660, 1),\n",
       " (634, 1),\n",
       " (502, 1),\n",
       " (1374, 1),\n",
       " (1180, 1),\n",
       " (792, 1),\n",
       " (463, 1),\n",
       " (776, 1),\n",
       " (1111, 1),\n",
       " (1118, 1),\n",
       " (1171, 1),\n",
       " (835, 1),\n",
       " (778, 1),\n",
       " (806, 1),\n",
       " (1344, 1),\n",
       " (765, 1),\n",
       " (1543, 1),\n",
       " (875, 1),\n",
       " (880, 1),\n",
       " (779, 1),\n",
       " (1081, 1),\n",
       " (503, 1),\n",
       " (825, 1),\n",
       " (917, 1),\n",
       " (801, 1),\n",
       " (684, 1),\n",
       " (915, 1),\n",
       " (879, 1),\n",
       " (1708, 1),\n",
       " (1075, 1),\n",
       " (1733, 1),\n",
       " (1684, 1),\n",
       " (549, 1),\n",
       " (1076, 1),\n",
       " (1012, 1),\n",
       " (1322, 1),\n",
       " (1235, 1),\n",
       " (703, 1),\n",
       " (1185, 1),\n",
       " (874, 1),\n",
       " (626, 1),\n",
       " (758, 1),\n",
       " (586, 1),\n",
       " (1577, 1),\n",
       " (1073, 1),\n",
       " (994, 1),\n",
       " (500, 1),\n",
       " (628, 1),\n",
       " (827, 1),\n",
       " (1022, 1),\n",
       " (708, 1),\n",
       " (804, 1),\n",
       " (749, 1),\n",
       " (578, 1),\n",
       " (648, 1),\n",
       " (929, 1),\n",
       " (1024, 1),\n",
       " (1048, 1),\n",
       " (667, 1),\n",
       " (1257, 1),\n",
       " (1126, 1),\n",
       " (1431, 1),\n",
       " (1291, 1),\n",
       " (674, 1),\n",
       " (1326, 1),\n",
       " (1147, 1),\n",
       " (572, 1),\n",
       " (655, 1),\n",
       " (783, 1),\n",
       " (939, 1),\n",
       " (807, 1),\n",
       " (700, 1),\n",
       " (627, 1),\n",
       " (713, 1),\n",
       " (1412, 1),\n",
       " (1450, 1),\n",
       " (1174, 1),\n",
       " (490, 1),\n",
       " (877, 1),\n",
       " (878, 1),\n",
       " (797, 1),\n",
       " (559, 1),\n",
       " (1587, 1),\n",
       " (1162, 1),\n",
       " (1370, 1),\n",
       " (1237, 1),\n",
       " (523, 1),\n",
       " (720, 1),\n",
       " (812, 1),\n",
       " (870, 1),\n",
       " (617, 1),\n",
       " (553, 1),\n",
       " (1183, 1),\n",
       " (659, 1),\n",
       " (609, 1),\n",
       " (1830, 1),\n",
       " (1085, 1),\n",
       " (1250, 1),\n",
       " (753, 1),\n",
       " (1615, 1),\n",
       " (773, 1),\n",
       " (1245, 1),\n",
       " (1202, 1),\n",
       " (670, 1),\n",
       " (1177, 1),\n",
       " (1504, 1),\n",
       " (829, 1),\n",
       " (1299, 1),\n",
       " (1244, 1),\n",
       " (695, 1),\n",
       " (1077, 1),\n",
       " (1325, 1),\n",
       " (821, 1)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "ctr = [(word,count) for word,count in Counter(data['count'].values).items()]\n",
    "ctr.sort(key=lambda x:x[1])\n",
    "ctr[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer = data[data['count'] > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<799061x259508 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15825468 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.fit_transform(data['2__gram'].str.join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('../data_with_n_grams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index(keys='comment_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(row):\n",
    "    return eval(row)\n",
    "data['2__gram'] = data['2_gram'].map(evaluate)\n",
    "# data['3__gram'] = data['3_gram'].map(evaluate)\n",
    "# data['4__gram'] = data['4_gram'].map(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_2=DataFrame(mlb.fit_transform(data['2__gram']),columns=mlb.classes_,index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['im guessing',\n",
       " 'guessing you',\n",
       " 'you buy',\n",
       " 'buy games',\n",
       " 'games on',\n",
       " 'on steam',\n",
       " 'steam gog',\n",
       " 'gog origin',\n",
       " 'origin uplay',\n",
       " 'uplay whats',\n",
       " 'whats wrong',\n",
       " 'wrong with',\n",
       " 'with windows',\n",
       " 'windows store']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(data['2_gram'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "source code string cannot contain null bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-d90049f75cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2_gram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: source code string cannot contain null bytes"
     ]
    }
   ],
   "source": [
    "enc.fit(eval(data['2_gram'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[\"['im guessing', 'guessing you', 'you buy', 'buy games', 'games on', 'on steam', 'steam gog', 'gog origin', 'origin uplay', 'uplay whats', 'whats wrong', 'wrong with', 'with windows', 'windows store']\"]]\n"
     ]
    }
   ],
   "source": [
    "f = enc.transform(data['2_gram'].values.reshape(-1,1))\n",
    "for rows in f:\n",
    "    print(rows.todense())\n",
    "    print(enc.inverse_transform(rows.todense()))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "4 16\n",
      "7 128\n",
      "10 1024\n",
      "13 8192\n",
      "16 65536\n",
      "19 524288\n",
      "22 4194304\n",
      "25 33554432\n",
      "28 268435456\n",
      "31 2147483648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 2\n",
    "for _ in range(1,33,3):\n",
    "#     x**=2\n",
    "    print(_,x**_)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndim = feature.shape[1]\n",
    "from copy import deepcopy\n",
    "def get_neuron_counts(n: int) -> list:\n",
    "    out = []\n",
    "    accumulator = 3\n",
    "#    out.append(n)\n",
    "    while accumulator < n:\n",
    "        out.append(accumulator)\n",
    "        accumulator **= 2\n",
    "    out.append(n)\n",
    "    sub = deepcopy(out[:-1])\n",
    "    out = out[::-1]\n",
    "    out.extend(sub[1:])\n",
    "    out.append(n)\n",
    "    #out.append(n)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3491207, 6561, 81, 9, 3, 9, 81, 6561, 3491207]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_neuron_counts(gram_2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_autoencoder(ngram):\n",
    "    model = Sequential()\n",
    "    for i,count in enumerate(get_neuron_counts(ngram.shape[1])):\n",
    "        if i == 0:\n",
    "            model.add(Dense(count, input_dim=count, activation='relu'))\n",
    "        elif count == 3:\n",
    "            model.add(Dense(count,activation='linear',name='bn'))\n",
    "        elif count == ngram.shape[1] and i != 0:\n",
    "            model.add(Dense(count,activation='sotfmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.to_csv('subset_of_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "spark = ps.sql.SparkSession\\\n",
    "        .builder\\\n",
    "        .master('local[4]')\\\n",
    "        .appName('capstone')\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[47865,47865] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Add] name: dense_1/kernel/Initializer/random_uniform/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-ff6db7daa7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-973afef7afa3>\u001b[0m in \u001b[0;36mmake_autoencoder\u001b[0;34m(ngram)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_neuron_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    176\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2141\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2142\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1028\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         shape=None):\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2508\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1404\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1535\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1537\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1539\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    118\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m       \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m       \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    798\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     return op(\n\u001b[0;32m--> 800\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    389\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[47865,47865] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Add] name: dense_1/kernel/Initializer/random_uniform/"
     ]
    }
   ],
   "source": [
    "mmake_autoencoder(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(neuron_counts)\n",
    "    model = Sequential([\n",
    "        Dense(ndim,input_dim=ndim,activation='relu'),\n",
    "       # Activation('relu'),\n",
    "        Dense(256,activation='relu'),\n",
    "       # Activation('relu'),\n",
    "        Dense(16,activation='relu'),\n",
    "      #  Activation('tanh'),\n",
    "        Dense(4,activation='relu'),\n",
    "      #  Activation('tanh'),\n",
    "        Dense(2,activation='linear',name='bottleneck'),\n",
    "      #  Activation('linear',name='bottleneck'),\n",
    "        Dense(4,activation='relu'),\n",
    "      #  Activation('tanh'),\n",
    "        Dense(16,activation='relu'),\n",
    "      #  Activation('relu'),\n",
    "        Dense(256,activation='relu'),\n",
    "       # Activation('relu'),\n",
    "        Dense(ndim)    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='adam',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 8s 16ms/sample - loss: 0.0020\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 0s 444us/sample - loss: 0.0020\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 0s 380us/sample - loss: 0.0020\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 0s 397us/sample - loss: 0.0020\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 0s 346us/sample - loss: 0.0020\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 0s 348us/sample - loss: 0.0020\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 0s 269us/sample - loss: 0.0020\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 0s 321us/sample - loss: 0.0020\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 0s 336us/sample - loss: 0.0020\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 0s 296us/sample - loss: 0.0020\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(feature.todense().astype(float),feature.todense().astype(float),batch_size=128,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f687830fe10>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 491)               241572    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               125952    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 491)               126187    \n",
      "=================================================================\n",
      "Total params: 502,345\n",
      "Trainable params: 502,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dense' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f9ac3618167b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Dense' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model.layers[4][feature[0].todense().astype(float)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layer_outputs=[feature.todense().astype(float)]\n",
    "for layer in model.layers:\n",
    "    layer_outputs.append( layer( layer_outputs[-1] ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 -- shape (500, 491)\n",
      "layer 2 -- shape (500, 491)\n",
      "layer 3 -- shape (500, 256)\n",
      "layer 4 -- shape (500, 16)\n",
      "layer 5 -- shape (500, 4)\n",
      "layer 6 -- shape (500, 2)\n",
      "layer 7 -- shape (500, 4)\n",
      "layer 8 -- shape (500, 16)\n",
      "layer 9 -- shape (500, 256)\n",
      "layer 10 -- shape (500, 491)\n"
     ]
    }
   ],
   "source": [
    "for i, ll in enumerate( layer_outputs ):\n",
    "    print( \"layer {} -- shape {}\".format(i+1, ll.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2771, shape=(500, 2), dtype=float32, numpy=\n",
       "array([[ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00851696, -0.00354056],\n",
       "       [ 0.00164961, -0.01630626],\n",
       "       [-0.00116533, -0.02076709],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00419633, -0.01071405],\n",
       "       [ 0.00501441, -0.01097406],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00437182, -0.01199236],\n",
       "       [ 0.00549238, -0.01021662],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.00570249, -0.0083591 ],\n",
       "       [ 0.00594804, -0.00949454],\n",
       "       [-0.00058731, -0.01985111],\n",
       "       [ 0.00550198, -0.0102014 ],\n",
       "       [ 0.00046543, -0.01818283],\n",
       "       [ 0.01364609,  0.00890641],\n",
       "       [ 0.00645177, -0.00855218],\n",
       "       [ 0.00585181, -0.00964703],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00839744,  0.00142766],\n",
       "       [ 0.00391639, -0.01271409],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00364558, -0.01314325],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00344982, -0.01345346],\n",
       "       [ 0.02514465,  0.03681018],\n",
       "       [ 0.00625128, -0.00901398],\n",
       "       [ 0.00946344,  0.00084724],\n",
       "       [ 0.00512795, -0.00425951],\n",
       "       [ 0.0227019 ,  0.03088231],\n",
       "       [ 0.00526387, -0.01057874],\n",
       "       [ 0.00461821, -0.00871213],\n",
       "       [ 0.00601626, -0.00938642],\n",
       "       [ 0.00731896, -0.00644776],\n",
       "       [ 0.00346352, -0.01343175],\n",
       "       [ 0.00410844, -0.00735692],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00703704, -0.0071319 ],\n",
       "       [-0.00198722, -0.01889896],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00455283, -0.01170552],\n",
       "       [ 0.00499311, -0.01100781],\n",
       "       [ 0.00656377, -0.00828039],\n",
       "       [-0.00099704, -0.02050041],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00818011, -0.00317859],\n",
       "       [ 0.00483067, -0.01126524],\n",
       "       [ 0.00559279, -0.00485981],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0127061 ,  0.00787477],\n",
       "       [ 0.01818447,  0.01991977],\n",
       "       [-0.00028501, -0.01937204],\n",
       "       [ 0.00655059, -0.00831237],\n",
       "       [-0.00319177, -0.0239784 ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0023781 , -0.01034102],\n",
       "       [ 0.00952312,  0.01436551],\n",
       "       [ 0.01495943,  0.01209352],\n",
       "       [ 0.00660302, -0.00743739],\n",
       "       [-0.00028148, -0.01936645],\n",
       "       [ 0.01448237,  0.01244775],\n",
       "       [ 0.01508143,  0.01372649],\n",
       "       [ 0.01096856,  0.0051873 ],\n",
       "       [-0.00970953, -0.03404262],\n",
       "       [ 0.01365254,  0.00892205],\n",
       "       [ 0.00540025, -0.01036261],\n",
       "       [ 0.00271723, -0.0146144 ],\n",
       "       [ 0.0052784 , -0.0085055 ],\n",
       "       [ 0.00063209, -0.01607634],\n",
       "       [ 0.01543276,  0.01622801],\n",
       "       [ 0.00174089, -0.01616161],\n",
       "       [ 0.01060017,  0.00423517],\n",
       "       [-0.00088886, -0.02032897],\n",
       "       [ 0.00149778, -0.01654686],\n",
       "       [ 0.00462623, -0.0115892 ],\n",
       "       [ 0.00646706, -0.00373507],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00839721,  0.00345895],\n",
       "       [ 0.02006274,  0.02582114],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00173102, -0.01617725],\n",
       "       [ 0.01448169,  0.01093417],\n",
       "       [ 0.00069444, -0.01781992],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0053316 , -0.00951563],\n",
       "       [ 0.00151671, -0.01317607],\n",
       "       [ 0.00032093, -0.01841181],\n",
       "       [ 0.00578519, -0.0097526 ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [-0.00010556, -0.01783294],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [-0.00116345, -0.02064059],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00197995, -0.01578276],\n",
       "       [ 0.00450529, -0.01178086],\n",
       "       [ 0.00117176, -0.01706351],\n",
       "       [ 0.00956419, -0.00099922],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00541055, -0.00827161],\n",
       "       [ 0.00527967, -0.0105537 ],\n",
       "       [ 0.00566269, -0.00994673],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01321425,  0.00785845],\n",
       "       [-0.00057638, -0.01983379],\n",
       "       [ 0.0210562 ,  0.02688865],\n",
       "       [ 0.00851633, -0.00354209],\n",
       "       [ 0.00410185, -0.00956237],\n",
       "       [ 0.00654933, -0.00598581],\n",
       "       [-0.00071326, -0.0200507 ],\n",
       "       [ 0.00253021, -0.01491077],\n",
       "       [ 0.00053416, -0.01613113],\n",
       "       [ 0.01814629,  0.02167584],\n",
       "       [ 0.00684872, -0.00403972],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00299118, -0.01418027],\n",
       "       [ 0.00551731, -0.00924413],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.0187145 ,  0.02426673],\n",
       "       [-0.00087679, -0.02030984],\n",
       "       [ 0.01220618,  0.0072799 ],\n",
       "       [ 0.01454566,  0.01108942],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00440051, -0.01161946],\n",
       "       [ 0.0166451 ,  0.02604541],\n",
       "       [ 0.01096856,  0.0036156 ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00307229, -0.00881737],\n",
       "       [ 0.0003261 , -0.0175863 ],\n",
       "       [ 0.00656775, -0.00827074],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00803606, -0.00417   ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00260279, -0.01479576],\n",
       "       [ 0.01073669,  0.00368755],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01018668,  0.00490669],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00658158, -0.00823718],\n",
       "       [ 0.00411214, -0.00954469],\n",
       "       [ 0.01655341,  0.01729283],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00348689, -0.01339472],\n",
       "       [ 0.00966586, -0.0007525 ],\n",
       "       [ 0.00031724, -0.01539713],\n",
       "       [ 0.0041543 , -0.01027546],\n",
       "       [ 0.01300519,  0.01043807],\n",
       "       [ 0.00304496, -0.01409505],\n",
       "       [-0.0032607 , -0.02408762],\n",
       "       [ 0.00521687, -0.01065323],\n",
       "       [ 0.00748222, -0.00605159],\n",
       "       [ 0.01369994,  0.00903709],\n",
       "       [-0.00380603, -0.02353776],\n",
       "       [ 0.01009738,  0.00029468],\n",
       "       [ 0.00658612, -0.00793663],\n",
       "       [-0.00347404, -0.02346543],\n",
       "       [ 0.00344874, -0.01323526],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00269307, -0.01465269],\n",
       "       [ 0.00457925, -0.01166366],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01193175,  0.01133791],\n",
       "       [ 0.01352885,  0.01020232],\n",
       "       [ 0.00488778, -0.01117473],\n",
       "       [ 0.00646395, -0.00336231],\n",
       "       [-0.00060425, -0.01987794],\n",
       "       [ 0.00138584, -0.01672425],\n",
       "       [-0.00046209, -0.01965267],\n",
       "       [-0.00085383, -0.02027346],\n",
       "       [ 0.00553392, -0.01015079],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0011585 , -0.01708452],\n",
       "       [ 0.01112139,  0.00415667],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00225528, -0.01170969],\n",
       "       [ 0.00933456,  0.00194232],\n",
       "       [ 0.0140056 ,  0.01130612],\n",
       "       [ 0.01285846,  0.00874106],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00293856, -0.01426365],\n",
       "       [ 0.00772904, -0.00545262],\n",
       "       [ 0.00372093, -0.01302384],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00326832, -0.0136566 ],\n",
       "       [ 0.00017222, -0.01864748],\n",
       "       [ 0.00387241, -0.01188838],\n",
       "       [-0.00069292, -0.02001847],\n",
       "       [ 0.0090216 , -0.0012913 ],\n",
       "       [ 0.00462634, -0.01045635],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [-0.0011124 , -0.02068321],\n",
       "       [ 0.00824825, -0.00419263],\n",
       "       [ 0.01498361,  0.0121522 ],\n",
       "       [ 0.01554882,  0.01731176],\n",
       "       [ 0.01513366,  0.01251632],\n",
       "       [ 0.00751838, -0.00596382],\n",
       "       [ 0.00543661, -0.00307662],\n",
       "       [ 0.00202814, -0.00449516],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00864232, -0.00323634],\n",
       "       [-0.00029061, -0.01843794],\n",
       "       [ 0.00614431, -0.0091835 ],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.00793065, -0.00496337],\n",
       "       [ 0.00334688, -0.00994005],\n",
       "       [-0.00543636, -0.02753539],\n",
       "       [ 0.01032547,  0.00084818],\n",
       "       [ 0.01560253,  0.0204009 ],\n",
       "       [ 0.00832944, -0.00014711],\n",
       "       [ 0.00469668, -0.01147756],\n",
       "       [ 0.01456243,  0.01353738],\n",
       "       [ 0.00269905, -0.01464321],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.01345074,  0.00843234],\n",
       "       [ 0.00484888, -0.00713463],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00453682, -0.00963453],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00029937, -0.01844599],\n",
       "       [-0.00430728, -0.02574614],\n",
       "       [ 0.01537596,  0.02069733],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01031169,  0.00081474],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00640278, -0.00865948],\n",
       "       [ 0.0009273 , -0.01245984],\n",
       "       [ 0.00258804, -0.01481913],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.004089  , -0.01244055],\n",
       "       [ 0.00427483, -0.01214607],\n",
       "       [ 0.00264902, -0.01472249],\n",
       "       [ 0.00594842, -0.00740895],\n",
       "       [-0.00101806, -0.02053371],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.00342479, -0.00987786],\n",
       "       [ 0.00334009, -0.00910407],\n",
       "       [-0.00210392, -0.02225447],\n",
       "       [ 0.00063061, -0.01558941],\n",
       "       [ 0.00801903, -0.00474888],\n",
       "       [ 0.00323472, -0.01379433],\n",
       "       [ 0.00582615, -0.0096877 ],\n",
       "       [-0.00042197, -0.01958909],\n",
       "       [ 0.0097674 ,  0.00094133],\n",
       "       [ 0.00654353, -0.00676568],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0138121 ,  0.0135525 ],\n",
       "       [ 0.00233612, -0.01521835],\n",
       "       [ 0.00425982, -0.01216985],\n",
       "       [-0.0007602 , -0.02012509],\n",
       "       [ 0.00436114, -0.0120093 ],\n",
       "       [ 0.01533348,  0.01786732],\n",
       "       [ 0.01532328,  0.01431656],\n",
       "       [ 0.00408862, -0.00673656],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00094205, -0.01742752],\n",
       "       [ 0.00059517, -0.01672739],\n",
       "       [ 0.00407881, -0.01238075],\n",
       "       [ 0.00592791, -0.00222262],\n",
       "       [ 0.00132016, -0.01682834],\n",
       "       [-0.00478111, -0.0247989 ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [-0.00128631, -0.02095881],\n",
       "       [ 0.00806167, -0.00347611],\n",
       "       [ 0.00384856, -0.01282158],\n",
       "       [ 0.01688685,  0.01677081],\n",
       "       [ 0.0039465 , -0.01266638],\n",
       "       [ 0.00291906, -0.0095024 ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00153117, -0.01559536],\n",
       "       [ 0.00532457, -0.00629641],\n",
       "       [ 0.00451353, -0.00819866],\n",
       "       [ 0.00786272, -0.00512821],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00540009, -0.01021984],\n",
       "       [ 0.01574684,  0.01400433],\n",
       "       [ 0.00510724, -0.01082695],\n",
       "       [ 0.0036625 , -0.01119236],\n",
       "       [ 0.00589793, -0.00957394],\n",
       "       [ 0.00563695, -0.00998751],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00219175, -0.01023463],\n",
       "       [-0.01068761, -0.03585705],\n",
       "       [-0.00854182, -0.03225899],\n",
       "       [ 0.01051821,  0.00545152],\n",
       "       [ 0.0038435 , -0.0128296 ],\n",
       "       [ 0.00588413, -0.00959581],\n",
       "       [ 0.00308304, -0.0140347 ],\n",
       "       [ 0.00306269, -0.01406696],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00483037, -0.01126571],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00231504, -0.01350789],\n",
       "       [ 0.00761652, -0.00048165],\n",
       "       [ 0.00299232, -0.00946369],\n",
       "       [ 0.004758  , -0.01138039],\n",
       "       [-0.0048605 , -0.02662283],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00509742, -0.01032785],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0095543 , -0.00102322],\n",
       "       [ 0.00082655, -0.01039056],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00811536, -0.00451513],\n",
       "       [ 0.00467961, -0.01150461],\n",
       "       [-0.00260293, -0.02304526],\n",
       "       [ 0.00821277,  0.00283827],\n",
       "       [ 0.0076858 , -0.00331498],\n",
       "       [ 0.00424159, -0.01219875],\n",
       "       [ 0.01392855,  0.00959186],\n",
       "       [ 0.0078442 , -0.00299148],\n",
       "       [-0.00542792, -0.02752202],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00518356, -0.00939631],\n",
       "       [ 0.00429765, -0.00803528],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0127277 ,  0.00667773],\n",
       "       [ 0.00179912, -0.01606933],\n",
       "       [-0.00258572, -0.02301799],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01444524,  0.01084572],\n",
       "       [ 0.01406736,  0.0099287 ],\n",
       "       [ 0.00378841, -0.0129169 ],\n",
       "       [ 0.01232411,  0.00833715],\n",
       "       [ 0.01073229,  0.00929031],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [-0.00828974, -0.0293189 ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00886688,  0.00138785],\n",
       "       [ 0.00144345, -0.01663295],\n",
       "       [ 0.002058  , -0.01565909],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00325104, -0.01376847],\n",
       "       [-0.00475578, -0.02645687],\n",
       "       [ 0.00406693, -0.01247554],\n",
       "       [ 0.00899462, -0.00238141],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00841124,  0.00030474],\n",
       "       [ 0.00256037, -0.00580203],\n",
       "       [ 0.00858078, -0.00338567],\n",
       "       [ 0.0056664 , -0.00994084],\n",
       "       [ 0.0058805 , -0.00960157],\n",
       "       [ 0.00437411, -0.00871987],\n",
       "       [ 0.00537113, -0.01040876],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00325763, -0.01375802],\n",
       "       [ 0.01259059,  0.00817026],\n",
       "       [-0.00108394, -0.02063811],\n",
       "       [ 0.00512084, -0.00456453],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01035137,  0.00176635],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01055942,  0.00878987],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00107594, -0.017202  ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.00632416, -0.00581509],\n",
       "       [ 0.00112143, -0.01714327],\n",
       "       [ 0.00425218, -0.01218196],\n",
       "       [ 0.0045541 , -0.01170352],\n",
       "       [-0.0011721 , -0.02067338],\n",
       "       [ 0.00603876, -0.00935077],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01051366,  0.00291904],\n",
       "       [ 0.00716119, -0.0033144 ],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00847573, -0.00364062],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.00722226, -0.004928  ],\n",
       "       [ 0.00130382, -0.01685423],\n",
       "       [ 0.02096163,  0.03050856],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00859955, -0.00257977],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01622292,  0.01657648],\n",
       "       [-0.00121801, -0.02085057],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00238783, -0.00667153],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.01104262,  0.00258851],\n",
       "       [ 0.00291191, -0.0143059 ],\n",
       "       [ 0.00079418, -0.01766186],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00889068,  0.00276917],\n",
       "       [ 0.0092635 ,  0.00061336],\n",
       "       [ 0.0043803 , -0.01197894],\n",
       "       [ 0.00523463, -0.01062507],\n",
       "       [ 0.00515594, -0.01074977],\n",
       "       [ 0.00651034, -0.00432689],\n",
       "       [ 0.01591926,  0.01442276],\n",
       "       [ 0.01137319,  0.01020618],\n",
       "       [-0.00406233, -0.02491453],\n",
       "       [-0.00050632, -0.01972276],\n",
       "       [-0.00464341, -0.02431601],\n",
       "       [ 0.001832  , -0.01601723],\n",
       "       [ 0.0059302 , -0.00952281],\n",
       "       [ 0.00022151, -0.01595046],\n",
       "       [ 0.00825954, -0.00169284],\n",
       "       [ 0.00530387, -0.01020698],\n",
       "       [ 0.00495957, -0.01106096],\n",
       "       [ 0.01011913,  0.00034745],\n",
       "       [-0.00045429, -0.0196403 ],\n",
       "       [ 0.01004565,  0.00016916],\n",
       "       [ 0.00477526, -0.01135304],\n",
       "       [ 0.01803902,  0.0195668 ],\n",
       "       [ 0.00653279, -0.00766016],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0094991 , -0.00115717],\n",
       "       [ 0.01243971,  0.00597885],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00037632, -0.01754586],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.0031686 , -0.01389911],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [-0.00647367, -0.02917923],\n",
       "       [ 0.00741467, -0.00164255],\n",
       "       [ 0.01042589,  0.00313831],\n",
       "       [ 0.0108385 ,  0.00209318],\n",
       "       [ 0.01036841,  0.004075  ],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00244678, -0.01504298],\n",
       "       [ 0.00411326, -0.01240212],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00513804, -0.00686784],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.0086028 , -0.00313854],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [-0.002927  , -0.02355882],\n",
       "       [ 0.00510786, -0.00704374],\n",
       "       [-0.0011948 , -0.02042735],\n",
       "       [ 0.0087653 , -0.0029379 ],\n",
       "       [ 0.0021711 , -0.01547985],\n",
       "       [-0.00363816, -0.02468578],\n",
       "       [ 0.00176718, -0.01545469],\n",
       "       [ 0.00654475, -0.00160545],\n",
       "       [ 0.00587646, -0.00960796],\n",
       "       [ 0.00458084, -0.01166113],\n",
       "       [ 0.01048668,  0.00396103],\n",
       "       [ 0.0091465 ,  0.00720708],\n",
       "       [-0.00357669, -0.02444066],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00120858, -0.00656587],\n",
       "       [ 0.00514367, -0.01076921],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00350238, -0.01337018],\n",
       "       [ 0.00404085, -0.01057042],\n",
       "       [-0.00259827, -0.02303787],\n",
       "       [ 0.00520081, -0.01067866],\n",
       "       [ 0.00963753,  0.00445831],\n",
       "       [ 0.00478585, -0.00631733],\n",
       "       [ 0.00845664, -0.00368694],\n",
       "       [ 0.0072209 , -0.003611  ],\n",
       "       [ 0.00737216, -0.00586807],\n",
       "       [ 0.00450499, -0.00973978],\n",
       "       [ 0.01145103,  0.00498437],\n",
       "       [ 0.00740373, -0.001991  ],\n",
       "       [ 0.00939581, -0.00140784],\n",
       "       [ 0.00067671, -0.01784801],\n",
       "       [ 0.00266987, -0.01468946],\n",
       "       [ 0.01030458,  0.00204887],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00855704, -0.0028563 ],\n",
       "       [ 0.00524873, -0.01060273],\n",
       "       [ 0.00612959, -0.00920682],\n",
       "       [ 0.00818025, -0.00096563],\n",
       "       [ 0.0008598 , -0.01755787],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00517169, -0.01072482],\n",
       "       [ 0.00628065, -0.00896744],\n",
       "       [ 0.00813145, -0.00447608],\n",
       "       [ 0.00140032, -0.0083385 ],\n",
       "       [-0.00106368, -0.02060601]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_outputs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import string\n",
    "import emoji\n",
    "from unicodedata import name\n",
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from pandas import Series\n",
    "\n",
    "#%%\n",
    "def remove_emoji(comment, replace_with_text=False):\n",
    "    '''\n",
    "    Helper function to remove emoji from a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:            str:    String to be cleaned\n",
    "    replace_with_text:  bool:   Whether or not the emoji will be \n",
    "                                    replaced or removed\n",
    "    Returns:\n",
    "    --------\n",
    "    str:    cleaned string\n",
    "    '''\n",
    "    if replace_with_text:\n",
    "        return replace_emoji(comment)\n",
    "    else:\n",
    "        return comment.encode('ascii','ignore').decode('ascii')\n",
    "\n",
    "def count_words(comment):\n",
    "    '''\n",
    "    Helper function to count the number of words in a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:       str: String whose words will be counted\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int:    number of words in string\n",
    "    '''\n",
    "    return len(comment.split())\n",
    "\n",
    "def get_grams(comment,n=2,keep_emoji_words=False):\n",
    "    '''\n",
    "    Returns n-grams for a sentence, optionally cleaning the string\n",
    "    in the process.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:            str:    sentence for which n-grams will be \n",
    "                                    made\n",
    "    n:                  int:    number of tokens to include in n-gram\n",
    "    keep_emoji_words:   bool:   whether emoji will be removed or \n",
    "                                    substituted with text \n",
    "                                    descriptions\n",
    "    Returns:\n",
    "    --------\n",
    "    list:   list of n-grams\n",
    "    '''\n",
    "    blob = TextBlob(clean_text(comment, keep_emoji_words=\\\n",
    "                                        keep_emoji_words))\n",
    "    return list([' '.join(wordlist) for wordlist in blob.ngrams(n)])\n",
    "# %%\n",
    "def clean_text(comment, keep_periods=True,\\\n",
    "                        keep_emoji_words=False):\n",
    "    '''\n",
    "    Removes all punctuation (and, optionally, emoji/non-ascii \n",
    "    characters) from a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:            str:    the string whose punctuation/emoji \n",
    "                                    will be removed\n",
    "    keep_periods:       bool:   whether or not periods will also be \n",
    "                                    removed\n",
    "    keep_emoji_words:   bool:   whether emoji will be removed or \n",
    "                                    replaced with string descriptions\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str:    cleaned text\n",
    "    '''\n",
    "    translation_dic = {key:None for key in string.punctuation}\n",
    "    if keep_periods:\n",
    "        del translation_dic['.']\n",
    "        tr_tab = str.maketrans(translation_dic)\n",
    "    else:\n",
    "        tr_tab = str.maketrans(translation_dic)\n",
    "    return remove_emoji(comment,keep_emoji_words).translate(tr_tab)\n",
    "\n",
    "def lemmatize(comment):\n",
    "    '''\n",
    "    Returns lemmatized version of reddit comment.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:        str:    comment to lemmatize\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    return_list:    str:  \n",
    "    '''\n",
    "    pass\n",
    "def count_emoji(comment):\n",
    "    '''\n",
    "    Function that counts number of emoji in a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:    str:    String from which number of emoji will be \n",
    "                            counted and returned\n",
    "    Returns:\n",
    "    --------\n",
    "    int:    number of emoji present in string\n",
    "    '''\n",
    "    return sum([\n",
    "        1 for character in comment \n",
    "            if character in emoji.UNICODE_EMOJI.keys()\n",
    "    ])\n",
    "def replace_emoji(comment):\n",
    "    '''\n",
    "    Function to replace emoji in a string.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    comment:    str:    String from which emoji will be replaced\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str:    Cleaned string where emoji have been repalced with ascii\n",
    "                characters describing the image\n",
    "    '''\n",
    "    return ''.join([\n",
    "        '_'.join(name(character).split())+' ' if character in\n",
    "        emoji.UNICODE_EMOJI else character for character\n",
    "        in comment\n",
    "    ])\n",
    "\n",
    "def stopwords_list(series,fraction = 0.2):\n",
    "    '''\n",
    "    Takes in a pandas.core.Series object, iterates over it, creating\n",
    "    a list of words, then finds the most frequently used words in the\n",
    "    corpus.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series:     pd.core.Series: Series whose words will be counted\n",
    "    fraction:   float: fraction of words to throw out\n",
    "\n",
    "    Returns:\n",
    "    list:   list of (fraction) most-frequently used words\n",
    "    '''\n",
    "    out = []\n",
    "    for elements in series:\n",
    "        cleaned = clean_text(elements,False,False)\n",
    "        num_words = count_words(cleaned)\n",
    "        if num_words > 1:\n",
    "            out.extend(cleaned.split())\n",
    "        elif num_words == 1:\n",
    "            out.append(cleaned)\n",
    "    ctr = [(word,count) for word,count in Counter(out).items()]\n",
    "    ctr.sort(key=lambda x:x[1])\n",
    "    ctr = ctr[::-1]\n",
    "    if not fraction:\n",
    "        return ctr\n",
    "    else:\n",
    "        cutoff_index = int(fraction*len(ctr))\n",
    "        stopwords = [word for word,number in ctr]\n",
    "        return stopwords[:cutoff_index]\n",
    "\n",
    "def series_grams(series,n=2):\n",
    "    '''\n",
    "    Function that returns a pandas.core.Series containing n-grams for\n",
    "    each row in the series that is passed to it.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    series: pd.core.series.Series: Series containing comments out of \n",
    "                                which n-grams are to be made\n",
    "    n:      int:            integer number of tokens to includ in \n",
    "                                each n-gram\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.core.series.Series\n",
    "    '''\n",
    "    out = []\n",
    "    for elements in series:\n",
    "        out.append(get_grams(elements.lower(),n))\n",
    "    return Series(out)\n",
    "\n",
    "\n",
    "# %%\n",
    "def all_ngrams(series):\n",
    "    '''\n",
    "    Takes pandas.core.Series as argument, iterates over it, and \n",
    "    returns a set of all n-grams present in the series.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    series: pd.core.series.Series: series containing lists of ngrams\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    out:    set:            set of all n-grams present in series\n",
    "    '''\n",
    "\n",
    "    out = set()\n",
    "    for elements in series:\n",
    "        for grams in elements:\n",
    "            out.add(grams)\n",
    "    return out\n",
    "\n",
    "def make_dummies(df, col_name):\n",
    "    '''\n",
    "    Makes dummy columns from df column containing list of n-grams.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df:         pd.core.frame.DataFrame:\n",
    "    col_name:   str:    name of column from which dummies will be made\n",
    "\n",
    "    Returns:\n",
    "    pandas.core.frame.DataFrame\n",
    "    '''\n",
    "\n",
    "    gram_set = all_ngrams(df[col_name])\n",
    "    for grams in gram_set:\n",
    "        df[grams] = Series([0]*df.shape[0])\n",
    "    for idx, row in df.iterrows():\n",
    "        for grms in row[col_name]:\n",
    "            df.loc[idx,grms] = 1\n",
    "    del df[col_name]\n",
    "    return df\n",
    "\n",
    "slurs = set([\n",
    "    'ching chong','chink','christ-killer','christ killer','gook',\n",
    "    'goy','half-breed','half breed', 'heeb','hebe','kike','jewboy',\n",
    "    'jigaboo','jiggabo', 'jig', 'jigga', 'jigger', 'jungle bunny',\n",
    "    'kyke','niglet','nig-nog', 'nig nog', 'nignog','nigger',\n",
    "    'nigga', 'nigress','niggah', 'nigga','porch monkey','raghead',\n",
    "    'rag head', 'sambo','shylock','slant-eye', 'slant eye','spic',\n",
    "    'spick','spik','tar baby','tar-baby','tyrone','towel head', \n",
    "    'uncle tom','wetback','beaner','camel jockey','coon-ass','coon',\n",
    "    'tnb','yard ape','welfare queen', 'unemployus', 'satchmo','sambo',\n",
    "    'race traitor','race-traitor','mammy','pickaninny','sheboon',\n",
    "    'furfag','chimpout','fag','faggot','queer','dyke','cocksucker'\n",
    "])\n",
    "def slurred(comment):\n",
    "    '''\n",
    "    Takes in a comment and returns either 1 (if slur is present) or 0\n",
    "    (if no slur is present).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    comment:    str:    string to parse for comments.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "\n",
    "    int: [0,1]\n",
    "    '''\n",
    "    comment_words = set(clean_text(comment,False,False).split())\n",
    "    return int(len(comment_words.intersection(slurs)) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "subset['slurred'] = subset['body'].map(slurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "subset['count'] = subset['reduced_sw'].map(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6031      4\n",
       "6032      7\n",
       "6033      2\n",
       "6034      3\n",
       "6035      3\n",
       "         ..\n",
       "792266    3\n",
       "792267    4\n",
       "792268    2\n",
       "792269    6\n",
       "792270    4\n",
       "Name: count, Length: 77477, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6031              [what find, find elephant, elephant tail]\n",
       "6032      [good hit, hit front, front page, page again, ...\n",
       "6033                                        [just interest]\n",
       "6034                                [so person, person rap]\n",
       "6035                             [was full, full americans]\n",
       "                                ...                        \n",
       "792266                             [bapu extra, extra hoga]\n",
       "792267                   [we respect, respect mr, mr beans]\n",
       "792268                                          [bharat ki]\n",
       "792269    [why how, how easy, easy settle, settle us, us...\n",
       "792270                            [hero chutiyapa, dna hai]\n",
       "Name: 2-gram, Length: 77477, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['2-gram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = cv.fit_transform(subset['reduced_sw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-47ff98f8b5ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2315\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/IPython/core/alias.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, rest)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;31m#-----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2451\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2453\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawnb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pexpect-U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<pexpect factory incomplete>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 303\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptyproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_spawnpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/site-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_native_pty_fork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Use internal fork_pty, for Solaris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/opt/anaconda2/envs/galvanize/lib/python3.7/pty.py\u001b[0m in \u001b[0;36mfork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmaster_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslave_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Establish a new session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
